---
title: "Monarch Butterfly Abundance Analysis (Updated Approach)"
format: pdf
editor: visual
---

## Setup and Libraries

```{r setup, message=FALSE, warning=FALSE}
# Load necessary libraries
library(tidyverse)
library(lubridate)
library(mgcv) # For GAMs
library(data.table) # For fast data prep
library(knitr) # For nice tables
```

## Load Raw Data
```{r}
# Load raw data
counts <- readr::read_csv("../data/butterfly_abundance_index.csv", show_col_types = FALSE)
deployments <- readr::read_csv("../data/deployments.csv", show_col_types = FALSE)
temp <- readr::read_csv("../data/temperature_data_2023.csv", show_col_types = FALSE)
wind <- readr::read_csv("../data/wind_all.csv", show_col_types = FALSE)

glimpse(counts)
glimpse(deployments)
glimpse(temp)
glimpse(wind)
```

## Data Prep
```{r}
# Filter and prepare deployments data
deployments_filtered <- deployments %>%
    filter(label_status == "Complete") %>%
    mutate(view_id = as.factor(view_id)) %>%
    select(deployment_id, view_id, wind_meter_name)

# Parse timestamps in counts data (YYYYMMDDHHMMSS in image_filename)
counts_with_datetime <- counts %>%
    mutate(
        datetime_str = stringr::str_extract(image_filename, "\\d{14}"),
        datetime     = lubridate::ymd_hms(datetime_str, tz = "UTC")
    ) %>%
    select(-datetime_str)

# Create master dataframe
master_df <- counts_with_datetime %>%
    left_join(deployments_filtered, by = "deployment_id") %>%
    left_join(temp, by = c("image_filename" = "filename"))

# Coerce critical time columns; keep wind in UTC as well
master_df <- master_df %>%
    mutate(
        view_id  = as.factor(view_id),
        datetime = as.POSIXct(datetime, tz = "UTC")
    )

# Wind table must have clear names: wind_meter_name, time, speed, gust
wind <- wind %>%
    mutate(
        time = as.POSIXct(time, tz = "UTC")
    )

cat("Master dataframe created with", nrow(master_df), "rows\n")
```

## Lag Builder Function

```{r}
# This version uses data.table non-equi joins to aggregate over [t-Δ, t] intervals
# per (view_id, wind_meter_name). It replaces the slow R loop.

prepare_lag_data <- function(master_df, wind_df, lag_minutes) {
    cat("Preparing data for", lag_minutes, "minute lag...\n")

    # Ensure unique column names in wind_df
    wind_df <- wind_df %>% rename(wind_time = time)

    df_t <- master_df %>%
        filter(!is.na(datetime) & !is.na(view_id))

    df_t_lag <- df_t %>%
        rename(
            abundance_t_minus_1        = total_butterflies,
            datetime_t_minus_1         = datetime,
            butterflies_sun_t_minus_1  = butterflies_direct_sun,
            temperature_t_minus_1      = temperature
        ) %>%
        mutate(datetime_expected = datetime_t_minus_1 + minutes(lag_minutes)) %>%
        select(
            view_id, datetime_t_minus_1, datetime_expected,
            abundance_t_minus_1, butterflies_sun_t_minus_1, temperature_t_minus_1
        )

    final_df <- df_t %>%
        left_join(
            df_t_lag,
            by = c("view_id" = "view_id", "datetime" = "datetime_expected")
        ) %>%
        filter(!is.na(abundance_t_minus_1)) %>%
        filter(!(total_butterflies == 0 & abundance_t_minus_1 == 0)) %>%
        mutate(
            time_delta_mins = as.numeric(difftime(datetime, datetime_t_minus_1, units = "mins")),
            butterfly_diff = total_butterflies - abundance_t_minus_1,
            butterfly_log_diff = log((total_butterflies + 0.1) / (abundance_t_minus_1 + 0.1))
        )

    cat("Valid pairs after filtering:", nrow(final_df), "\n")
    if (nrow(final_df) == 0) {
        return(final_df[0, ])
    }

    intervals <- final_df %>%
        select(view_id, wind_meter_name, datetime_t_minus_1, datetime) %>%
        distinct() %>%
        mutate(interval_id = dplyr::row_number())

    wind_dt <- as.data.table(wind_df)
    master_dt <- as.data.table(master_df)
    ints_dt <- as.data.table(intervals)

    setkey(wind_dt, wind_meter_name, wind_time)
    setkey(master_dt, view_id, datetime)

    # Now use wind_time in non-equi join (remove duplicate wind_time from join)
    wind_ag <- wind_dt[
        ints_dt,
        on = .(
            wind_meter_name,
            wind_time >= datetime_t_minus_1,
            wind_time <= datetime
        ),
        allow.cartesian = TRUE,
        nomatch = 0L
    ][, .(
        interval_id                  = interval_id[1L],
        mean_wind_speed              = mean(speed, na.rm = TRUE),
        max_wind_speed               = suppressWarnings(max(gust, na.rm = TRUE)),
        sd_wind_speed                = sd(speed, na.rm = TRUE),
        cumulative_wind              = sum(speed, na.rm = TRUE),
        gust_factor                  = mean(gust, na.rm = TRUE) / mean(speed, na.rm = TRUE),
        sustained_minutes_above_2mps = sum(speed > 2, na.rm = TRUE),
        gust_minutes_above_2mps      = sum(gust > 2, na.rm = TRUE)
    ), by = .(wind_meter_name, interval_id)]


    # Guard against all-NA => max = -Inf
    if (nrow(wind_ag)) {
        wind_ag[, max_wind_speed := ifelse(is.finite(max_wind_speed), max_wind_speed, NA_real_)]
        wind_ag[, gust_factor := ifelse(is.finite(gust_factor), gust_factor, NA_real_)]
    }

    # TEMPERATURE & SUNLIGHT metrics over [start, end]
    master_ag <- master_dt[
        ints_dt,
        on = .(
            view_id,
            datetime >= datetime_t_minus_1,
            datetime <= datetime
        ),
        allow.cartesian = TRUE,
        nomatch = 0L
    ][,
        {
            props <- ifelse(total_butterflies > 0,
                butterflies_direct_sun / total_butterflies,
                NA_real_
            )
            sum_total <- sum(total_butterflies, na.rm = TRUE)
            sum_sun <- sum(butterflies_direct_sun, na.rm = TRUE)
            sunlight_prop <- if (sum_total > 0) sum_sun / sum_total else NA_real_

            pmax <- suppressWarnings(max(props, na.rm = TRUE))
            pmin <- suppressWarnings(min(props, na.rm = TRUE))
            psd <- sd(props, na.rm = TRUE)
            pmax <- ifelse(is.finite(pmax), pmax, NA_real_)
            pmin <- ifelse(is.finite(pmin), pmin, NA_real_)
            psd <- ifelse(is.finite(psd), psd, NA_real_)

            .(
                interval_id         = interval_id[1L],
                mean_temp           = mean(temperature, na.rm = TRUE),
                max_temp            = suppressWarnings(max(temperature, na.rm = TRUE)),
                min_temp            = suppressWarnings(min(temperature, na.rm = TRUE)),
                sd_temp             = sd(temperature, na.rm = TRUE),
                sunlight_proportion = sunlight_prop,
                max_prop_sunlight   = pmax,
                min_prop_sunlight   = pmin,
                sd_prop_sunlight    = psd
            )
        },
        by = .(view_id, interval_id)
    ]

    if (nrow(master_ag)) {
        master_ag[, `:=`(
            max_temp = ifelse(is.finite(max_temp), max_temp, NA_real_),
            min_temp = ifelse(is.finite(min_temp), min_temp, NA_real_)
        )]
    }

    # Merge metrics back to the matched pairs
    # First select only unique columns from each dataset before merging
    wind_ag_clean <- wind_ag[, .(
        interval_id, mean_wind_speed, max_wind_speed,
        sd_wind_speed, cumulative_wind, gust_factor, 
        sustained_minutes_above_2mps, gust_minutes_above_2mps
    )]
    master_ag_clean <- master_ag[, .(
        interval_id, mean_temp, max_temp, min_temp,
        sd_temp, sunlight_proportion, max_prop_sunlight,
        min_prop_sunlight, sd_prop_sunlight
    )]
    metrics <- merge(wind_ag_clean, master_ag_clean, by = "interval_id", all = TRUE)

    final_out <- final_df %>%
        left_join(intervals, by = c("view_id", "wind_meter_name", "datetime_t_minus_1", "datetime")) %>%
        left_join(metrics, by = "interval_id") %>%
        select(-interval_id) %>%
        filter(!is.na(mean_wind_speed) & !is.na(mean_temp)) %>%
        arrange(view_id, datetime) %>%
        group_by(view_id) %>%
        mutate(time_index = row_number()) %>%
        ungroup()
    
    # Add GAM and LOESS smoothed predictions
    cat("Computing GAM and LOESS smoothed predictions...\n")
    
    # GAM smoothed predictions
    final_out <- final_out %>%
        group_by(view_id) %>%
        do({
            if (nrow(.) >= 10) {  # Need minimum observations for smoothing
                tryCatch({
                    # GAM smoothing
                    gam_mod <- gam(total_butterflies ~ s(as.numeric(datetime)), 
                                   data = ., method = "REML")
                    gam_fitted <- predict(gam_mod, newdata = .)
                    
                    # LOESS smoothing
                    if (nrow(.) >= 3) {
                        loess_fitted <- predict(loess(total_butterflies ~ as.numeric(datetime), 
                                                     data = ., span = 0.3), newdata = .)
                    } else {
                        loess_fitted <- .$total_butterflies
                    }
                    
                    data.frame(., 
                              gam_fitted_count = gam_fitted,
                              loess_fitted_count = loess_fitted)
                }, error = function(e) {
                    cat("Warning: Could not fit smoothers for view_id", .$view_id[1], "\n")
                    data.frame(., 
                              gam_fitted_count = .$total_butterflies,
                              loess_fitted_count = .$total_butterflies)
                })
            } else {
                # Too few observations - use raw counts
                data.frame(., 
                          gam_fitted_count = .$total_butterflies,
                          loess_fitted_count = .$total_butterflies)
            }
        }) %>%
        ungroup()
    
    # Compute differences from smoothed predictions and add t-1 fitted values
    final_out <- final_out %>%
        group_by(view_id) %>%
        arrange(datetime) %>%
        mutate(
            gam_fitted_count_t_minus_1 = lag(gam_fitted_count),
            loess_fitted_count_t_minus_1 = lag(loess_fitted_count),
            gam_pred_diff = gam_fitted_count - lag(gam_fitted_count),
            loess_pred_diff = loess_fitted_count - lag(loess_fitted_count),
            gam_log_diff = log((gam_fitted_count + 0.1) / (lag(gam_fitted_count) + 0.1)),
            loess_log_diff = log((loess_fitted_count + 0.1) / (lag(loess_fitted_count) + 0.1))
        ) %>%
        ungroup()

    cat("Final dataset rows:", nrow(final_out), "\n")
    if (nrow(final_out) > 0) {
        cat(
            "Time delta range:",
            round(min(final_out$time_delta_mins, na.rm = TRUE), 1), "to",
            round(max(final_out$time_delta_mins, na.rm = TRUE), 1), "minutes\n"
        )
    }

    final_out
}
```

## Generate Lag Datasets

```{r}
cat("=== GENERATING LAG DATASETS ===\n")

data_30m <- prepare_lag_data(master_df, wind, lag_minutes = 30)
data_120m <- prepare_lag_data(master_df, wind, lag_minutes = 120)
data_240m <- prepare_lag_data(master_df, wind, lag_minutes = 240)

cat("\n=== DATASET SUMMARY ===\n")
cat("30-minute lag dataset:", nrow(data_30m), "observations\n")
cat("2-hour   lag dataset:", nrow(data_120m), "observations\n")
cat("4-hour   lag dataset:", nrow(data_240m), "observations\n")
```

## Exploratory Analysis

```{r}
# Load additional libraries for visualization and correlation analysis
library(corrplot)
library(GGally)
library(patchwork)

# Function to create histograms for a dataset
create_histograms <- function(data, dataset_name) {
    cat(paste0("\n=== HISTOGRAMS FOR: ", dataset_name, " ===\n"))
    
    # Response variables
    p1 <- ggplot(data, aes(x = total_butterflies)) +
        geom_histogram(bins = 30, fill = "lightblue", alpha = 0.7) +
        labs(title = "Total Butterflies (Response)", x = "Count") +
        theme_minimal()
    
    p2 <- ggplot(data, aes(x = butterfly_diff)) +
        geom_histogram(bins = 30, fill = "lightcoral", alpha = 0.7) +
        labs(title = "Butterfly Difference", x = "Difference") +
        theme_minimal()
    
    p3 <- ggplot(data, aes(x = butterfly_log_diff)) +
        geom_histogram(bins = 30, fill = "lightgreen", alpha = 0.7) +
        labs(title = "Log Butterfly Difference", x = "Log Difference") +
        theme_minimal()
    
    # GAM fitted response variables
    p3a <- ggplot(data, aes(x = gam_fitted_count)) +
        geom_histogram(bins = 30, fill = "cyan", alpha = 0.7) +
        labs(title = "GAM Fitted Count", x = "Count") +
        theme_minimal()
    
    p3b <- ggplot(data, aes(x = gam_pred_diff)) +
        geom_histogram(bins = 30, fill = "darkgreen", alpha = 0.7) +
        labs(title = "GAM Predicted Difference", x = "Difference") +
        theme_minimal()
    
    p3c <- ggplot(data, aes(x = loess_fitted_count)) +
        geom_histogram(bins = 30, fill = "lightpink", alpha = 0.7) +
        labs(title = "LOESS Fitted Count", x = "Count") +
        theme_minimal()
    
    p3d <- ggplot(data, aes(x = loess_pred_diff)) +
        geom_histogram(bins = 30, fill = "darkmagenta", alpha = 0.7) +
        labs(title = "LOESS Predicted Difference", x = "Difference") +
        theme_minimal()
    
    # Lagged predictors
    p4 <- ggplot(data, aes(x = abundance_t_minus_1)) +
        geom_histogram(bins = 30, fill = "orange", alpha = 0.7) +
        labs(title = "Abundance (t-1)", x = "Count") +
        theme_minimal()
    
    p4a <- ggplot(data, aes(x = gam_fitted_count_t_minus_1)) +
        geom_histogram(bins = 30, fill = "turquoise", alpha = 0.7) +
        labs(title = "GAM Fitted Count (t-1)", x = "Count") +
        theme_minimal()
    
    p4b <- ggplot(data, aes(x = loess_fitted_count_t_minus_1)) +
        geom_histogram(bins = 30, fill = "plum", alpha = 0.7) +
        labs(title = "LOESS Fitted Count (t-1)", x = "Count") +
        theme_minimal()
    
    # Wind predictors
    p5 <- ggplot(data, aes(x = mean_wind_speed)) +
        geom_histogram(bins = 30, fill = "steelblue", alpha = 0.7) +
        labs(title = "Mean Wind Speed", x = "m/s") +
        theme_minimal()
    
    p6 <- ggplot(data, aes(x = max_wind_speed)) +
        geom_histogram(bins = 30, fill = "navy", alpha = 0.7) +
        labs(title = "Max Wind Speed (Gust)", x = "m/s") +
        theme_minimal()
    
    p7 <- ggplot(data, aes(x = cumulative_wind)) +
        geom_histogram(bins = 30, fill = "darkblue", alpha = 0.7) +
        labs(title = "Cumulative Wind", x = "Total m/s") +
        theme_minimal()
    
    p8 <- ggplot(data, aes(x = sustained_minutes_above_2mps)) +
        geom_histogram(bins = 30, fill = "purple", alpha = 0.7) +
        labs(title = "Sustained Minutes > 2 m/s", x = "Minutes") +
        theme_minimal()
    
    # Temperature predictors
    p9 <- ggplot(data, aes(x = mean_temp)) +
        geom_histogram(bins = 30, fill = "red", alpha = 0.7) +
        labs(title = "Mean Temperature", x = "°C") +
        theme_minimal()
    
    p10 <- ggplot(data, aes(x = max_temp)) +
        geom_histogram(bins = 30, fill = "darkred", alpha = 0.7) +
        labs(title = "Max Temperature", x = "°C") +
        theme_minimal()
    
    # Sunlight predictors
    p11 <- ggplot(data, aes(x = sunlight_proportion)) +
        geom_histogram(bins = 30, fill = "gold", alpha = 0.7) +
        labs(title = "Sunlight Proportion", x = "Proportion") +
        theme_minimal()
    
    p12 <- ggplot(data, aes(x = max_prop_sunlight)) +
        geom_histogram(bins = 30, fill = "orange", alpha = 0.7) +
        labs(title = "Max Sunlight Proportion", x = "Proportion") +
        theme_minimal()
    
    # Print individual plots (will appear on separate pages in PDF)
    print(p1)
    print(p2)
    print(p3)
    print(p3a)
    print(p3b)
    print(p3c)
    print(p3d)
    print(p4)
    print(p4a)
    print(p4b)
    print(p5)
    print(p6)
    print(p7)
    print(p8)
    print(p9)
    print(p10)
    print(p11)
    print(p12)
    
    return(list(p1, p2, p3, p3a, p3b, p3c, p3d, p4, p4a, p4b, p5, p6, p7, p8, p9, p10, p11, p12))
}

# Function to create correlation matrix and plot
create_correlation_analysis <- function(data, dataset_name) {
    cat(paste0("\n=== CORRELATION ANALYSIS FOR: ", dataset_name, " ===\n"))
    
    # Select numeric variables for correlation analysis
    numeric_vars <- data %>%
        select(
            total_butterflies, butterfly_diff, butterfly_log_diff,
            abundance_t_minus_1, butterflies_sun_t_minus_1, temperature_t_minus_1,
            mean_wind_speed, max_wind_speed, sd_wind_speed, cumulative_wind,
            gust_factor, sustained_minutes_above_2mps, gust_minutes_above_2mps,
            mean_temp, max_temp, min_temp, sd_temp,
            sunlight_proportion, max_prop_sunlight, min_prop_sunlight, sd_prop_sunlight
        ) %>%
        na.omit()
    
    # Calculate correlation matrix
    cor_matrix <- cor(numeric_vars, use = "complete.obs")
    
    # Create correlation plot
    corrplot(cor_matrix, 
             method = "color", 
             type = "upper",
             order = "hclust",
             tl.cex = 0.8,
             tl.col = "black",
             tl.srt = 45,
             title = paste("Correlation Matrix -", dataset_name),
             mar = c(0,0,1,0))
    
    # Print highly correlated pairs (>0.7 or <-0.7)
    high_cor <- which(abs(cor_matrix) > 0.7 & cor_matrix != 1, arr.ind = TRUE)
    if (nrow(high_cor) > 0) {
        cat("\nHighly correlated variable pairs (|r| > 0.7):\n")
        for (i in 1:nrow(high_cor)) {
            row_var <- rownames(cor_matrix)[high_cor[i, 1]]
            col_var <- colnames(cor_matrix)[high_cor[i, 2]]
            cor_val <- cor_matrix[high_cor[i, 1], high_cor[i, 2]]
            cat(sprintf("%s <-> %s: r = %.3f\n", row_var, col_var, cor_val))
        }
    }
    
    return(cor_matrix)
}
```

```{r}
# Run exploratory analysis for 30-minute lag data (most observations)
if (nrow(data_30m) > 0) {
    hist_30m <- create_histograms(data_30m, "30-Minute Lag")
    cor_30m <- create_correlation_analysis(data_30m, "30-Minute Lag")
}
```

```{r}
# Run exploratory analysis for 2-hour lag data
if (nrow(data_120m) > 0) {
    hist_120m <- create_histograms(data_120m, "2-Hour Lag")
    cor_120m <- create_correlation_analysis(data_120m, "2-Hour Lag")
}
```

## Models

### 30 min
```{r}
library(nlme)

# Mixed model with AR(1) correlation structure within view_id
model_lme <- lme(
  gam_pred_diff ~ gam_fitted_count_t_minus_1,
  random = ~1 | view_id,
  #correlation = corAR1(form = ~ time_index | view_id), # time_index = observation order within view
  na.action = na.omit,
  data = data_240m,
  method = "REML"
)

summary(model_lme)

# Diagnostics
plot(model_lme)                   # residuals vs fitted, QQ plot
acf(resid(model_lme, type="normalized")) # residual autocorrelation check


```
```{r}
library(mgcv)

data_30m$datetime_num <- as.numeric(data_30m$datetime)

gam_model <- gam(
  total_butterflies ~ 
    s(datetime_num, k = 40) +              # smooth time trend
    s(mean_wind_speed, k = 10) +                # smooth wind effect
    s(mean_temp, k = 10) +                      # smooth temp effect
    sunlight_proportion +                       # linear or smooth
    s(view_id, bs = "re"),                      # random intercepts
  data = data_30m,
  method = "REML"
)

summary(gam_model)
plot(gam_model, pages = 1, shade = TRUE)

```
```{r}
# Ensure view_id is a factor for use as a random effect and in 'by' variables
data_30m$view_id <- as.factor(data_30m$view_id)

# Build the null model
# Response: gam_pred_diff ~ The change in smoothed butterfly counts
# Predictors:
#   s(time_index, by = view_id, k = 10) -> A smooth of time, with a *different* trend for each view_id. 
#                                          'k=10' is a reasonable starting point to prevent overfitting.
#   gam_fitted_count_t_minus_1         -> The smoothed abundance at the previous time step (t-1). This helps
#                                          account for whether changes are happening from a high or low baseline.
#   s(view_id, bs = "re")              -> A random effect for view_id, which accounts for baseline differences
#                                          in abundance between sites.
null_model <- gam(
  gam_pred_diff ~ s(time_index, by = view_id, k = 10) +
                  gam_fitted_count_t_minus_1 +
                  s(view_id, bs = "re"),
  data = data_30m,
  method = "REML",
  na.action = na.omit
)

# Get the summary of the model
summary(null_model)

# Check the model diagnostics
# This is crucial! It tells you if 'k' is large enough.
# Look for low p-values in the output of this function.
gam.check(null_model)

# Plot the model results
# This will show you the unique time trend for each site.
plot(null_model, pages = 1, shade = TRUE, seWithMean = TRUE)
```

```{r}
# Load the parallel library
library(parallel)

# Detect the number of available cores
num_cores <- detectCores()

# Create a cluster, leaving one core free for system processes
cl <- makeCluster(num_cores - 1)

# Run bam() using the cluster for parallel processing
null_model_scat <- bam(
  gam_pred_diff ~ s(time_index, by = view_id, k = 10) +
                  gam_fitted_count_t_minus_1 +
                  s(view_id, bs = "re"),
  family = scat(link = 'identity'),
  data = data_30m,
  na.action = na.omit,
  cluster = cl # Pass the cluster object here
)

# Don't forget to stop the cluster when you're done!
stopCluster(cl)

summary(null_model_scat)
```

```{r}
# A more stable hierarchical model structure
# s(time_index) -> The average "global" time trend across all sites.
# s(time_index, view_id, bs = "fs") -> The "factor-smooth" interaction. This models
#                                     how each site's trend deviates from the global
#                                     average. This is much more stable than fitting
#                                     totally separate smooths.
# We'll use bam() and the gaussian family to ensure convergence first.

hierarchical_model <- bam(
  gam_pred_diff ~ s(time_index, k = 20) +
                  s(time_index, view_id, bs = "fs", k = 5) +
                  gam_fitted_count_t_minus_1 +
                  s(view_id, bs = "re"),
  family = gaussian(),
  data = data_30m,
  na.action = na.omit
)

# Check for convergence warnings first!
# Then examine the summary.
summary(hierarchical_model)

# Plot the diagnostics. Is the "fan shape" in the residuals still there?
plot(hierarchical_model, pages = 1, shade = TRUE)
```

```{r}
# Load the parallel library
library(parallel)

# Detect the number of available CPU cores on your machine
num_cores <- detectCores()

# Create a "cluster" of processes, leaving one core free for system stability
cl <- makeCluster(num_cores - 1)

# Fit the final null model using bam() and distribute the work across the cluster
final_null_model <- bam(
  gam_pred_diff ~ s(time_index, k = 20) +
                  s(time_index, view_id, bs = "fs", k = 5) +
                  gam_fitted_count_t_minus_1 +
                  s(view_id, bs = "re"),
  family = scat(),
  data = data_240m,
  na.action = na.omit,
  cluster = cl # Assign the cluster to the model
)

# Stop the cluster once the model has finished running
stopCluster(cl)

# Check the results
summary(final_null_model)
gam.check(final_null_model)
```
```{r}
# 1. Create a transformed response variable using the cube root.
#    The sign() function preserves the negative values.
data_30m$gam_pred_diff_cubert <- sign(data_30m$gam_pred_diff) * (abs(data_30m$gam_pred_diff))^(1/3)

# 2. Fit the model to this NEW response variable.
#    Since we transformed the data, we go back to the fast and simple gaussian() family.
#    We will also increase 'k' slightly to be safe.
final_null_model_transformed <- bam(
  gam_pred_diff_cubert ~ s(time_index, k = 30) +
                         s(time_index, view_id, bs = "fs", k = 10) +
                         gam_fitted_count_t_minus_1 +
                         s(view_id, bs = "re"),
  family = gaussian(),
  data = data_30m,
  na.action = na.omit
)

# 3. Check the diagnostics of this new model.
summary(final_null_model_transformed)
gam.check(final_null_model_transformed)
```
```{r}
# 1. Build the full model by adding environmental predictors
full_model <- bam(
  gam_pred_diff_cubert ~ s(time_index, k = 30) +
                         s(time_index, view_id, bs = "fs", k = 10) +
                         gam_fitted_count_t_minus_1 +
                         s(view_id, bs = "re") +
                         # --- ADDING ENVIRONMENTAL PREDICTORS ---
                         s(mean_wind_speed, k = 10) +
                         s(mean_temp, k = 10) +
                         s(sunlight_proportion, k = 5),
  family = gaussian(),
  data = data_30m,
  na.action = na.omit
)

# 2. Check the summary of the full model
# Look at the p-values for the new environmental terms.
summary(full_model)
```

```{r}
# Formally compare the null model to the full environmental model
anova(final_null_model_transformed, full_model, test = "F")
```

