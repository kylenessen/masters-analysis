---
title: "Monarch Butterfly Abundance Analysis: 30-Minute Lag (Bayesian)"
author: "Analysis Report"
date: "`r Sys.Date()`"
format: html
---

# Monarch Butterfly Abundance Analysis: 30-Minute Lag with Bayesian GAMs

## Setup and Data Loading

```{r setup, message=FALSE, warning=FALSE}
library(tidyverse)
library(lubridate)
library(brms)  # for Bayesian GAM models
library(corrplot)
library(knitr)
library(bayesplot)  # for Bayesian diagnostic plots

# Set options for better performance
options(mc.cores = parallel::detectCores())
```

```{r load-data}
counts <- read_csv("../data/butterfly_abundance_index.csv")
deployments <- read_csv("../data/deployments.csv")
temp <- read_csv("../data/temperature_data_2023.csv")
wind <- read_csv("../data/wind_all.csv")

cat("Data loaded successfully\n")
cat("Counts rows:", nrow(counts), "\n")
cat("Deployments rows:", nrow(deployments), "\n")
cat("Temperature rows:", nrow(temp), "\n")
cat("Wind rows:", nrow(wind), "\n")
```

## Data Cleaning and Merging

```{r data-cleaning}
# Filter and select deployments data
deployments_filtered <- deployments %>%
  filter(label_status == "Complete") %>%
  mutate(view_id = as.factor(view_id)) %>%
  select(deployment_id, view_id, wind_meter_name)

cat("Filtered deployments to", nrow(deployments_filtered), "complete records\n")
```

```{r parse-timestamps}
# Parse timestamps in counts data
counts_with_datetime <- counts %>%
  mutate(
    datetime_str = str_extract(image_filename, "\\d{14}"),
    datetime = ymd_hms(datetime_str)
  ) %>%
  select(-datetime_str)

cat("Parsed", sum(!is.na(counts_with_datetime$datetime)), "valid timestamps\n")
```

```{r merge-dataframes}
# Create master dataframe
master_df <- counts_with_datetime %>%
  left_join(deployments_filtered, by = "deployment_id") %>%
  left_join(temp, by = c("image_filename" = "filename"))

cat("Master dataframe created with", nrow(master_df), "rows\n")
cat("Columns:", paste(names(master_df), collapse = ", "), "\n")

# Check for completeness
complete_records <- master_df %>%
  filter(!is.na(view_id) & !is.na(temperature) & !is.na(datetime))
cat("Complete records with all key fields:", nrow(complete_records), "\n")
```

## Lagged Data Preparation Function

```{r lag-function}
prepare_lag_data <- function(master_df, wind_df, lag_minutes) {
  cat("Preparing data for", lag_minutes, "minute lag...\n")
  
  # Create time-shifted dataframes
  df_t <- master_df %>%
    filter(!is.na(datetime) & !is.na(view_id))
  
  df_t_lag <- df_t %>%
    rename(
      abundance_t_minus_1 = total_butterflies,
      datetime_t_minus_1 = datetime,
      butterflies_sun_t_minus_1 = butterflies_direct_sun,
      temperature_t_minus_1 = temperature
    ) %>%
    select(view_id, datetime_t_minus_1, abundance_t_minus_1, 
           butterflies_sun_t_minus_1, temperature_t_minus_1)
  
  # Perform sliding window join
  df_t_lag <- df_t_lag %>%
    mutate(datetime_expected = datetime_t_minus_1 + minutes(lag_minutes))
  
  final_df <- df_t %>%
    left_join(
      df_t_lag,
      by = c("view_id" = "view_id", "datetime" = "datetime_expected")
    )
  
  # Filter invalid pairs
  final_df <- final_df %>%
    filter(!is.na(abundance_t_minus_1)) %>%
    filter(!(total_butterflies == 0 & abundance_t_minus_1 == 0))
  
  cat("Valid pairs after filtering:", nrow(final_df), "\n")
  
  if(nrow(final_df) == 0) {
    cat("No valid pairs found, returning empty dataframe\n")
    return(data.frame())
  }
  
  # More efficient calculation using data.table-style operations
  cat("Calculating interval predictors efficiently...\n")
  
  # Pre-sort and index the data for faster lookups
  wind_sorted <- wind_df %>%
    arrange(wind_meter_name, time) %>%
    mutate(wind_id = row_number())
  
  master_sorted <- master_df %>%
    arrange(view_id, datetime) %>%
    mutate(master_id = row_number())
  
  # Calculate time delta first (fast operation)
  final_df <- final_df %>%
    mutate(time_delta_mins = as.numeric(difftime(datetime, datetime_t_minus_1, units = "mins")))
  
  # Batch process by unique combinations to reduce redundant calculations
  unique_intervals <- final_df %>%
    select(view_id, wind_meter_name, datetime_t_minus_1, datetime) %>%
    distinct() %>%
    mutate(interval_id = row_number())
  
  cat("Processing", nrow(unique_intervals), "unique intervals...\n")
  
  # Initialize progress tracking
  pb_intervals <- nrow(unique_intervals)
  
  # Calculate metrics for each unique interval
  interval_metrics <- list()
  
  for(i in 1:nrow(unique_intervals)) {
    if(i %% max(1, floor(pb_intervals/10)) == 0) {
      cat("Progress:", round(100*i/pb_intervals, 1), "%\n")
    }
    
    interval <- unique_intervals[i, ]
    
    # Wind metrics for this interval
    wind_subset <- wind_sorted %>%
      filter(
        wind_meter_name == interval$wind_meter_name,
        time >= interval$datetime_t_minus_1,
        time <= interval$datetime
      )
    
    if (nrow(wind_subset) > 0) {
      wind_metrics <- list(
        mean_wind_speed = mean(wind_subset$speed, na.rm = TRUE),
        max_wind_speed = max(wind_subset$speed, na.rm = TRUE),
        sd_wind_speed = sd(wind_subset$speed, na.rm = TRUE),
        gust_factor = mean(wind_subset$gust, na.rm = TRUE) / mean(wind_subset$speed, na.rm = TRUE),
        minutes_above_2mps = sum(wind_subset$speed > 2, na.rm = TRUE)
      )
    } else {
      wind_metrics <- list(
        mean_wind_speed = NA_real_,
        max_wind_speed = NA_real_,
        sd_wind_speed = NA_real_,
        gust_factor = NA_real_,
        minutes_above_2mps = NA_real_
      )
    }
    
    # Temperature and sunlight metrics for this interval
    temp_subset <- master_sorted %>%
      filter(
        view_id == interval$view_id,
        datetime >= interval$datetime_t_minus_1,
        datetime <= interval$datetime
      )
    
    if (nrow(temp_subset) > 0) {
      # Temperature metrics
      temp_metrics <- list(
        mean_temp = mean(temp_subset$temperature, na.rm = TRUE),
        max_temp = max(temp_subset$temperature, na.rm = TRUE),
        min_temp = min(temp_subset$temperature, na.rm = TRUE),
        sd_temp = sd(temp_subset$temperature, na.rm = TRUE)
      )
      
      # Sunlight metrics
      total_sun <- sum(temp_subset$butterflies_direct_sun, na.rm = TRUE)
      total_count <- sum(temp_subset$total_butterflies, na.rm = TRUE)
      if (total_count > 0) {
        overall_prop <- total_sun / total_count
        obs_props <- ifelse(temp_subset$total_butterflies > 0,
                           temp_subset$butterflies_direct_sun / temp_subset$total_butterflies,
                           NA_real_)
        sun_metrics <- list(
          sunlight_proportion = overall_prop,
          max_prop_sunlight = max(obs_props, na.rm = TRUE),
          min_prop_sunlight = min(obs_props, na.rm = TRUE),
          sd_prop_sunlight = sd(obs_props, na.rm = TRUE)
        )
      } else {
        sun_metrics <- list(
          sunlight_proportion = NA_real_,
          max_prop_sunlight = NA_real_,
          min_prop_sunlight = NA_real_,
          sd_prop_sunlight = NA_real_
        )
      }
    } else {
      temp_metrics <- list(
        mean_temp = NA_real_,
        max_temp = NA_real_,
        min_temp = NA_real_,
        sd_temp = NA_real_
      )
      sun_metrics <- list(
        sunlight_proportion = NA_real_,
        max_prop_sunlight = NA_real_,
        min_prop_sunlight = NA_real_,
        sd_prop_sunlight = NA_real_
      )
    }
    
    # Store all metrics for this interval
    interval_metrics[[i]] <- c(
      interval_id = interval$interval_id,
      wind_metrics,
      temp_metrics,
      sun_metrics
    )
  }
  
  # Convert to dataframe
  cat("Combining results...\n")
  metrics_df <- do.call(rbind, lapply(interval_metrics, as.data.frame))
  
  # Join back with original data
  final_df_with_intervals <- final_df %>%
    left_join(unique_intervals, by = c("view_id", "wind_meter_name", "datetime_t_minus_1", "datetime")) %>%
    left_join(metrics_df, by = "interval_id") %>%
    select(-interval_id)
  
  # Remove rows with too many NAs in predictors
  final_clean <- final_df_with_intervals %>%
    filter(!is.na(mean_wind_speed) & !is.na(mean_temp))
  
  # CRITICAL: Sort data for brms autocorrelation structure
  # Data must be sorted by grouping variable (view_id) and then by time (datetime)
  final_clean <- final_clean %>%
    arrange(view_id, datetime)
  
  cat("Final dataset rows:", nrow(final_clean), "\n")
  if(nrow(final_clean) > 0) {
    cat("Time delta range:", round(min(final_clean$time_delta_mins, na.rm = TRUE), 1),
        "to", round(max(final_clean$time_delta_mins, na.rm = TRUE), 1), "minutes\n")
  }
  
  return(final_clean)
}
```

## 30-Minute Lag Analysis

```{r lag-30min}
data_30m <- prepare_lag_data(master_df, wind, lag_minutes = 30)
```

### Data Quality Check

```{r data-check}
cat("Data structure summary:\n")
cat("Total rows:", nrow(data_30m), "\n")
cat("Complete cases:", sum(complete.cases(data_30m)), "\n")
cat("Rows with abundance_t_minus_1 > 0:", sum(data_30m$abundance_t_minus_1 > 0, na.rm = TRUE), "\n")
cat("Rows with total_butterflies > 0:", sum(data_30m$total_butterflies > 0, na.rm = TRUE), "\n")
cat("Unique view_ids:", length(unique(data_30m$view_id)), "\n")
cat("Time range:", as.character(range(data_30m$datetime, na.rm = TRUE)), "\n")
```

## Data Preparation for Modeling

```{r prepare-model-data}
# Prepare data for brms modeling
required_vars <- c("total_butterflies", "abundance_t_minus_1", "mean_wind_speed", 
                  "mean_temp", "sunlight_proportion", "view_id", "datetime")

# Check all required variables are present
missing_vars <- required_vars[!required_vars %in% names(data_30m)]
if(length(missing_vars) > 0) {
  stop("Missing required variables: ", paste(missing_vars, collapse = ", "))
}

# Prepare clean dataset for modeling
model_data <- data_30m %>%
  select(all_of(required_vars)) %>%
  na.omit() %>%
  arrange(view_id, datetime)  # Critical for autocorrelation structure

cat("Model data prepared:\n")
cat("- Observations:", nrow(model_data), "\n")
cat("- Variables:", ncol(model_data), "\n")
cat("- View IDs:", length(unique(model_data$view_id)), "\n")
cat("- Time range:", as.character(range(model_data$datetime)), "\n")

# Check for sufficient variation
view_counts <- table(model_data$view_id)
cat("- Min/Max observations per view:", min(view_counts), "/", max(view_counts), "\n")
```

## Bayesian GAM Model

```{r}
# --- Step 2: Define Priors ---
# These are weakly informative priors to help stabilize this complex model.
my_priors <- c(
  prior(student_t(3, 0, 2.5), class = "Intercept"),
  prior(normal(0, 1), class = "sds"),
  prior(normal(0, 1), class = "ar")
)

# --- Step 3: Run the brms Model ---
# This model is complex and will take a significant amount of time to run.
# Using 4000 iterations is a robust starting point.

additive_model_brms <- brm(
  # Define the model formula
  bf(total_butterflies ~ s(abundance_t_minus_1, k = 20) + 
                         s(mean_wind_speed) + 
                         s(mean_temp) + 
                         s(sunlight_proportion) +
                         (1 | view_id) + 
                         ar(time = datetime, gr = view_id, p = 1)),
  
  data = model_data,
  family = negbinomial(),
  prior = my_priors,
  
  # Set a sufficient number of iterations for convergence
  iter = 4000, 
  warmup = 1000, 
  
  # Use multiple cores for parallel processing
  chains = 8, 
  cores = 8,
  
  # The cmdstanr backend can be faster if you have it installed
  # install.packages("cmdstanr", repos = c("https://mc-stan.org/r-packages/", getOption("repos")))
  # cmdstanr::install_cmdstan()
  backend = "cmdstanr",
  
  # Save model compilation to avoid re-compiling
  file = "additive_model_brms"
)

# --- Step 4: Check the Results ---
# Once it's finished, you can view the summary
summary(additive_model_brms)

# And look at the diagnostic plots
plot(additive_model_brms)
```



## Model Diagnostics

```{r model-diagnostics, fig.width=10, fig.height=8}
# Check model convergence and diagnostics
cat("=== MODEL DIAGNOSTICS ===\n")

# Basic convergence checks
cat("Model fitted successfully:", !is.null(additive_model_brms), "\n")
cat("Number of observations:", nrow(model_data), "\n")
cat("Number of view IDs:", length(unique(model_data$view_id)), "\n")

# Convergence diagnostics
tryCatch({
  rhat_values <- rhat(additive_model_brms)
  ess_values <- neff_ratio(additive_model_brms)
  
  cat("R-hat (max):", round(max(rhat_values, na.rm = TRUE), 3), "\n")
  cat("Effective sample size (min ratio):", round(min(ess_values, na.rm = TRUE), 3), "\n")
  
  # Check convergence
  if (max(rhat_values, na.rm = TRUE) < 1.01) {
    cat("âœ“ Excellent convergence (R-hat < 1.01)\n")
  } else if (max(rhat_values, na.rm = TRUE) < 1.1) {
    cat("âœ“ Good convergence (R-hat < 1.1)\n")
  } else {
    cat("âš  Warning: Poor convergence (R-hat >= 1.1)\n")
  }
  
  if (min(ess_values, na.rm = TRUE) > 0.1) {
    cat("âœ“ Sufficient effective sample size\n")
  } else {
    cat("âš  Warning: Low effective sample size\n")
  }
  
}, error = function(e) {
  cat("Error accessing convergence diagnostics:", e$message, "\n")
})

# Posterior predictive check
print(pp_check(additive_model_brms, ndraws = 100) + 
      labs(title = "Posterior Predictive Check: Additive Model"))

# Trace plots for key parameters
plot(additive_model_brms, ask = FALSE)
```

## Model Results

```{r model-results}
# Model summary
print(summary(additive_model_brms))

# Calculate model comparison metrics
tryCatch({
  loo_result <- loo(additive_model_brms)
  cat("\nModel Performance:\n")
  cat("LOO-CV IC:", round(loo_result$estimates["looic", "Estimate"], 2), "\n")
  cat("LOO-CV SE:", round(loo_result$estimates["looic", "SE"], 2), "\n")
}, error = function(e) {
  cat("Could not calculate LOO-CV:", e$message, "\n")
})

cat("\nðŸŽ‰ Model fitting complete!\n")
```