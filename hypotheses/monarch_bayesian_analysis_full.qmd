---
title: "Monarch Butterfly Abundance: Full Bayesian GAM Analysis"
author: "Analysis Report"
date: "`r Sys.Date()`"
format: html
---

# Monarch Butterfly Abundance: Bayesian GAM Analysis Across Multiple Time Lags

This document fits Bayesian GAM models across 30-minute, 2-hour, and 4-hour time lags to understand how environmental factors influence monarch butterfly abundance.

## Setup and Data Loading

```{r setup, message=FALSE, warning=FALSE}
library(brms)
library(tidyverse)
library(lubridate)
library(knitr)
library(bayesplot)
library(data.table) # high-performance joins/aggregations
library(future)      # parallel processing
library(furrr)       # parallel purrr functions

# Use CmdStanR backend for performance
options(brms.backend = "cmdstanr")

# Setup parallel processing for 24-core machine
# Running 3 models at a time (same model type across lag intervals)
# This uses 3 × 4 = 12 cores, leaving plenty of headroom
plan(multisession, workers = 12)  # Use 12 cores total

cat("Bayesian GAM Analysis Setup Complete\n")
cat("Backend:", getOption("brms.backend"), "\n")
cat("Parallel workers:", nbrOfWorkers(), "\n")
```

```{r load-data, message=FALSE}
# Load raw data
counts <- readr::read_csv("../data/butterfly_abundance_index.csv", show_col_types = FALSE)
deployments <- readr::read_csv("../data/deployments.csv", show_col_types = FALSE)
temp <- readr::read_csv("../data/temperature_data_2023.csv", show_col_types = FALSE)
wind <- readr::read_csv("../data/wind_all.csv", show_col_types = FALSE)

cat("Data loaded successfully\n")
cat("Counts rows:", nrow(counts), "\n")
cat("Deployments rows:", nrow(deployments), "\n")
cat("Temperature rows:", nrow(temp), "\n")
cat("Wind rows:", nrow(wind), "\n")
```

## Data Preparation

```{r data-preparation, message=FALSE}
# Filter and prepare deployments data
deployments_filtered <- deployments %>%
    filter(label_status == "Complete") %>%
    mutate(view_id = as.factor(view_id)) %>%
    select(deployment_id, view_id, wind_meter_name)

# Parse timestamps in counts data (YYYYMMDDHHMMSS in image_filename)
counts_with_datetime <- counts %>%
    mutate(
        datetime_str = stringr::str_extract(image_filename, "\\d{14}"),
        datetime     = lubridate::ymd_hms(datetime_str, tz = "UTC")
    ) %>%
    select(-datetime_str)

# Create master dataframe
master_df <- counts_with_datetime %>%
    left_join(deployments_filtered, by = "deployment_id") %>%
    left_join(temp, by = c("image_filename" = "filename"))

# Coerce critical time columns; keep wind in UTC as well
master_df <- master_df %>%
    mutate(
        view_id  = as.factor(view_id),
        datetime = as.POSIXct(datetime, tz = "UTC")
    )

# Wind table must have clear names: wind_meter_name, time, speed, gust
wind <- wind %>%
    mutate(
        time = as.POSIXct(time, tz = "UTC")
    )

cat("Master dataframe created with", nrow(master_df), "rows\n")
```

## Super-fast lag builder (vectorized, no loops)

```{r lag-function, message=FALSE}
# This version uses data.table non-equi joins to aggregate over [t-Δ, t] intervals
# per (view_id, wind_meter_name). It replaces the slow R loop.

prepare_lag_data <- function(master_df, wind_df, lag_minutes) {
    cat("Preparing data for", lag_minutes, "minute lag...\n")

    # Ensure unique column names in wind_df
    wind_df <- wind_df %>% rename(wind_time = time)

    df_t <- master_df %>%
        filter(!is.na(datetime) & !is.na(view_id))

    df_t_lag <- df_t %>%
        rename(
            abundance_t_minus_1        = total_butterflies,
            datetime_t_minus_1         = datetime,
            butterflies_sun_t_minus_1  = butterflies_direct_sun,
            temperature_t_minus_1      = temperature
        ) %>%
        mutate(datetime_expected = datetime_t_minus_1 + minutes(lag_minutes)) %>%
        select(
            view_id, datetime_t_minus_1, datetime_expected,
            abundance_t_minus_1, butterflies_sun_t_minus_1, temperature_t_minus_1
        )

    final_df <- df_t %>%
        left_join(
            df_t_lag,
            by = c("view_id" = "view_id", "datetime" = "datetime_expected")
        ) %>%
        filter(!is.na(abundance_t_minus_1)) %>%
        filter(!(total_butterflies == 0 & abundance_t_minus_1 == 0)) %>%
        mutate(
            time_delta_mins = as.numeric(difftime(datetime, datetime_t_minus_1, units = "mins"))
        )

    cat("Valid pairs after filtering:", nrow(final_df), "\n")
    if (nrow(final_df) == 0) {
        return(final_df[0, ])
    }

    intervals <- final_df %>%
        select(view_id, wind_meter_name, datetime_t_minus_1, datetime) %>%
        distinct() %>%
        mutate(interval_id = dplyr::row_number())

    wind_dt <- as.data.table(wind_df)
    master_dt <- as.data.table(master_df)
    ints_dt <- as.data.table(intervals)

    setkey(wind_dt, wind_meter_name, wind_time)
    setkey(master_dt, view_id, datetime)

    # Now use wind_time in non-equi join (remove duplicate wind_time from join)
    wind_ag <- wind_dt[
        ints_dt,
        on = .(
            wind_meter_name,
            wind_time >= datetime_t_minus_1,
            wind_time <= datetime
        ),
        allow.cartesian = TRUE,
        nomatch = 0L
    ][, .(
        interval_id        = interval_id[1L],
        mean_wind_speed    = mean(speed, na.rm = TRUE),
        max_wind_speed     = suppressWarnings(max(speed, na.rm = TRUE)),
        sd_wind_speed      = sd(speed, na.rm = TRUE),
        gust_factor        = mean(gust, na.rm = TRUE) / mean(speed, na.rm = TRUE),
        minutes_above_2mps = sum(speed > 2, na.rm = TRUE)
    ), by = .(wind_meter_name, interval_id)]


    # Guard against all-NA => max = -Inf
    if (nrow(wind_ag)) {
        wind_ag[, max_wind_speed := ifelse(is.finite(max_wind_speed), max_wind_speed, NA_real_)]
        wind_ag[, gust_factor := ifelse(is.finite(gust_factor), gust_factor, NA_real_)]
    }

    # TEMPERATURE & SUNLIGHT metrics over [start, end]
    master_ag <- master_dt[
        ints_dt,
        on = .(
            view_id,
            datetime >= datetime_t_minus_1,
            datetime <= datetime
        ),
        allow.cartesian = TRUE,
        nomatch = 0L
    ][, {
        props <- ifelse(total_butterflies > 0,
            butterflies_direct_sun / total_butterflies,
            NA_real_
        )
        sum_total <- sum(total_butterflies, na.rm = TRUE)
        sum_sun <- sum(butterflies_direct_sun, na.rm = TRUE)
        sunlight_prop <- if (sum_total > 0) sum_sun / sum_total else NA_real_

        pmax <- suppressWarnings(max(props, na.rm = TRUE))
        pmin <- suppressWarnings(min(props, na.rm = TRUE))
        psd <- sd(props, na.rm = TRUE)
        pmax <- ifelse(is.finite(pmax), pmax, NA_real_)
        pmin <- ifelse(is.finite(pmin), pmin, NA_real_)
        psd <- ifelse(is.finite(psd), psd, NA_real_)

        .(
            interval_id         = interval_id[1L],
            mean_temp           = mean(temperature, na.rm = TRUE),
            max_temp            = suppressWarnings(max(temperature, na.rm = TRUE)),
            min_temp            = suppressWarnings(min(temperature, na.rm = TRUE)),
            sd_temp             = sd(temperature, na.rm = TRUE),
            sunlight_proportion = sunlight_prop,
            max_prop_sunlight   = pmax,
            min_prop_sunlight   = pmin,
            sd_prop_sunlight    = psd
        )
    }, by = .(view_id, interval_id)]

    if (nrow(master_ag)) {
        master_ag[, `:=`(
            max_temp = ifelse(is.finite(max_temp), max_temp, NA_real_),
            min_temp = ifelse(is.finite(min_temp), min_temp, NA_real_)
        )]
    }

    # Merge metrics back to the matched pairs
    # First select only unique columns from each dataset before merging
    wind_ag_clean <- wind_ag[, .(interval_id, mean_wind_speed, max_wind_speed, 
                                  sd_wind_speed, gust_factor, minutes_above_2mps)]
    master_ag_clean <- master_ag[, .(interval_id, mean_temp, max_temp, min_temp, 
                                      sd_temp, sunlight_proportion, max_prop_sunlight, 
                                      min_prop_sunlight, sd_prop_sunlight)]
    metrics <- merge(wind_ag_clean, master_ag_clean, by = "interval_id", all = TRUE)

    final_out <- final_df %>%
        left_join(intervals, by = c("view_id", "wind_meter_name", "datetime_t_minus_1", "datetime")) %>%
        left_join(metrics, by = "interval_id") %>%
        select(-interval_id) %>%
        filter(!is.na(mean_wind_speed) & !is.na(mean_temp)) %>%
        arrange(view_id, datetime)

    cat("Final dataset rows:", nrow(final_out), "\n")
    if (nrow(final_out) > 0) {
        cat(
            "Time delta range:",
            round(min(final_out$time_delta_mins, na.rm = TRUE), 1), "to",
            round(max(final_out$time_delta_mins, na.rm = TRUE), 1), "minutes\n"
        )
    }

    final_out
}
```

## Generate Lag Datasets

```{r generate-datasets}
cat("=== GENERATING LAG DATASETS ===\n")

data_30m <- prepare_lag_data(master_df, wind, lag_minutes = 30)
data_120m <- prepare_lag_data(master_df, wind, lag_minutes = 120)
data_240m <- prepare_lag_data(master_df, wind, lag_minutes = 240)

cat("\n=== DATASET SUMMARY ===\n")
cat("30-minute lag dataset:", nrow(data_30m), "observations\n")
cat("2-hour   lag dataset:", nrow(data_120m), "observations\n")
cat("4-hour   lag dataset:", nrow(data_240m), "observations\n")
```

## Bayesian Modeling Setup

```{r modeling-setup}
# ===============================================================
# SETUP
# ===============================================================

# SAMPLING OPTION: Set to TRUE for testing, FALSE for full analysis
USE_SAMPLE <- TRUE
SAMPLE_SIZE <- 300

# More informative priors to help with convergence
my_priors <- c(
    prior(student_t(3, 0, 2.5), class = "Intercept"),
    prior(normal(0, 0.5), class = "sds"),  # Tighter prior on smooth terms
    prior(normal(0.5, 0.3), class = "ar"),  # Expect positive autocorrelation
    prior(exponential(1), class = "shape")  # Prior for negative binomial dispersion
)

# Parallelization plan for a 24-core machine
# Since threading is disabled with AR models, we run all chains in parallel
# With 24 cores, we could run 6 models simultaneously (4 cores each)
CHAINS <- 4 # standard for diagnostics
CORES <- 4 # run all 4 chains in parallel
# THREADS disabled due to AR terms

# Adjust iterations based on whether we're testing or running full analysis
if (USE_SAMPLE) {
    ITER <- 2000   # Increased for better sampling
    WARMUP <- 1000  # Increased warmup for better adaptation
    cat("Using testing iterations: ITER =", ITER, ", WARMUP =", WARMUP, "\n")
} else {
    ITER <- 4000   # Full analysis
    WARMUP <- 2000 # Increased warmup for full analysis
}

SEED <- 20250812

# Updated control parameters to address divergences and E-BFMI warnings
ctrl <- list(
    adapt_delta = 0.95,     # Increased from 0.9 to reduce divergences
    max_treedepth = 15,     # Increased from 12 for complex posteriors
    stepsize = 0.01         # Smaller stepsize for better exploration
)

cat("Parallel plan (24-core machine):\n")
cat(
    "  chains =", CHAINS,
    "| cores per model =", CORES,
    "| potential parallel models =", floor(24/CORES), "\n"
)
cat("Note: With AR terms, within-chain threading is disabled\n")
cat("Consider using future/furrr to run multiple models in parallel\n")

# Helper to standardize common brms args
# Note: Threading disabled due to AR terms in models
brms_common <- list(
    family          = negbinomial(),
    prior           = my_priors,
    iter            = ITER,
    warmup          = WARMUP,
    chains          = CHAINS,
    cores           = CORES,  # Use all 4 cores for 4 chains
    # threads       = threading(THREADS), # Disabled - not supported with AR models
    seed            = SEED,
    backend         = "cmdstanr",
    control         = ctrl,
    save_pars       = save_pars(all = TRUE),
    file_refit      = "on_change" # only refit if formula/data/prior changed
)

# Convenience wrapper to splice common args safely
fit_brm <- function(formula, data, file) {
    do.call(
        what = brms::brm,
        args = c(list(
            formula = formula,
            data    = data,
            file    = file
        ), brms_common)
    )
}

# Prep function to ensure ordering/vars for AR structure
prepare_brms_data <- function(df) {
    required_vars <- c(
        "total_butterflies", "abundance_t_minus_1", "mean_wind_speed",
        "mean_temp", "sunlight_proportion", "view_id", "datetime"
    )
    missing_vars <- setdiff(required_vars, names(df))
    if (length(missing_vars) > 0) {
        stop("Missing required variables: ", paste(missing_vars, collapse = ", "))
    }
    df %>%
        select(all_of(required_vars)) %>%
        tidyr::drop_na() %>%
        arrange(view_id, datetime)
}

# Prepare the datasets for modeling
cat("Preparing datasets for brms modeling...\n")

if (USE_SAMPLE) {
    cat("\n*** USING SAMPLED DATA FOR TESTING ***\n")
    cat("Sample size:", SAMPLE_SIZE, "observations per dataset\n\n")
    
    set.seed(SEED)  # Ensure reproducible sampling
    
    # Sample from each dataset
    data_30m_brms <- prepare_brms_data(data_30m) %>%
        sample_n(min(SAMPLE_SIZE, n()))
    
    data_120m_brms <- prepare_brms_data(data_120m) %>%
        sample_n(min(SAMPLE_SIZE, n()))
    
    data_240m_brms <- prepare_brms_data(data_240m) %>%
        sample_n(min(SAMPLE_SIZE, n()))
} else {
    cat("\n*** USING FULL DATA ***\n")
    data_30m_brms <- prepare_brms_data(data_30m)
    data_120m_brms <- prepare_brms_data(data_120m)
    data_240m_brms <- prepare_brms_data(data_240m)
}

cat("\n=== BRMS-READY DATASETS ===\n")
cat("30-minute:", nrow(data_30m_brms), "observations\n")
cat("2-hour:   ", nrow(data_120m_brms), "observations\n")
cat("4-hour:   ", nrow(data_240m_brms), "observations\n")
```

## Model Fitting

### Model Fitting Strategy

We'll run the same model type across all three lag intervals simultaneously.
This allows for better comparison and uses 3 models × 4 cores = 12 cores at a time,
leaving headroom for system processes.

### Baseline Models (All Lag Intervals)

```{r models-baseline}
cat("\n=== FITTING BASELINE MODELS ACROSS ALL LAG INTERVALS ===\n")
cat("Running 3 models in parallel (30min, 2hr, 4hr)...\n\n")

# Define baseline model formula
# Reduced k from 20 to 10 for smoother splines and better convergence
baseline_formula <- bf(total_butterflies ~ s(abundance_t_minus_1, k = 10) +
                       (1 | view_id) +
                       ar(time = datetime, gr = view_id, p = 1))

# Prepare data and file names
file_prefix <- if (USE_SAMPLE) "sample_" else ""
datasets <- list(
    "30m" = data_30m_brms,
    "120m" = data_120m_brms,
    "240m" = data_240m_brms
)
files_baseline <- paste0(file_prefix, "brm_", names(datasets), "_base.rds")

# Run baseline models for all lag intervals in parallel
results_baseline <- future_map2(
    datasets, files_baseline,
    ~fit_brm(baseline_formula, data = .x, file = .y),
    .options = furrr_options(seed = TRUE),
    .progress = TRUE
)

# Assign to individual objects
names(results_baseline) <- paste0("brm_", names(datasets), "_base")
list2env(results_baseline, envir = .GlobalEnv)

cat("Baseline models complete!\n")
```

### Wind Models (All Lag Intervals)

```{r models-wind}
cat("\n=== FITTING WIND MODELS ACROSS ALL LAG INTERVALS ===\n")
cat("Running 3 models in parallel (30min, 2hr, 4hr)...\n\n")

# Define wind model formula
wind_formula <- bf(total_butterflies ~ s(abundance_t_minus_1, k = 10) +
                   s(mean_wind_speed, k = 10) +
                   (1 | view_id) +
                   ar(time = datetime, gr = view_id, p = 1))

files_wind <- paste0(file_prefix, "brm_", names(datasets), "_wind.rds")

# Run wind models for all lag intervals in parallel
results_wind <- future_map2(
    datasets, files_wind,
    ~fit_brm(wind_formula, data = .x, file = .y),
    .options = furrr_options(seed = TRUE),
    .progress = TRUE
)

# Assign to individual objects
names(results_wind) <- paste0("brm_", names(datasets), "_wind")
list2env(results_wind, envir = .GlobalEnv)

cat("Wind models complete!\n")
```

### Temperature Models (All Lag Intervals)

```{r models-temp}
cat("\n=== FITTING TEMPERATURE MODELS ACROSS ALL LAG INTERVALS ===\n")
cat("Running 3 models in parallel (30min, 2hr, 4hr)...\n\n")

# Define temperature model formula
temp_formula <- bf(total_butterflies ~ s(abundance_t_minus_1, k = 10) +
                   s(mean_temp, k = 10) +
                   (1 | view_id) +
                   ar(time = datetime, gr = view_id, p = 1))

files_temp <- paste0(file_prefix, "brm_", names(datasets), "_temp.rds")

# Run temperature models for all lag intervals in parallel
results_temp <- future_map2(
    datasets, files_temp,
    ~fit_brm(temp_formula, data = .x, file = .y),
    .options = furrr_options(seed = TRUE),
    .progress = TRUE
)

# Assign to individual objects
names(results_temp) <- paste0("brm_", names(datasets), "_temp")
list2env(results_temp, envir = .GlobalEnv)

cat("Temperature models complete!\n")
```

### Additive Models (All Lag Intervals)

```{r models-additive}
cat("\n=== FITTING ADDITIVE MODELS ACROSS ALL LAG INTERVALS ===\n")
cat("Running 3 models in parallel (30min, 2hr, 4hr)...\n\n")

# Define additive model formula
additive_formula <- bf(total_butterflies ~ s(abundance_t_minus_1, k = 10) +
                       s(mean_wind_speed, k = 10) +
                       s(mean_temp, k = 10) +
                       s(sunlight_proportion, k = 10) +
                       (1 | view_id) +
                       ar(time = datetime, gr = view_id, p = 1))

files_additive <- paste0(file_prefix, "brm_", names(datasets), "_additive.rds")

# Run additive models for all lag intervals in parallel
results_additive <- future_map2(
    datasets, files_additive,
    ~fit_brm(additive_formula, data = .x, file = .y),
    .options = furrr_options(seed = TRUE),
    .progress = TRUE
)

# Assign to individual objects
names(results_additive) <- paste0("brm_", names(datasets), "_additive")
list2env(results_additive, envir = .GlobalEnv)

cat("Additive models complete!\n")
```

### Interaction Models (All Lag Intervals)

```{r models-interaction}
cat("\n=== FITTING INTERACTION MODELS ACROSS ALL LAG INTERVALS ===\n")
cat("Running 3 models in parallel (30min, 2hr, 4hr)...\n\n")

# Define interaction model formula
interaction_formula <- bf(total_butterflies ~ s(abundance_t_minus_1, k = 10) +
                          s(mean_wind_speed, k = 10) +
                          t2(mean_temp, sunlight_proportion, k = c(5, 5)) +
                          (1 | view_id) +
                          ar(time = datetime, gr = view_id, p = 1))

files_interaction <- paste0(file_prefix, "brm_", names(datasets), "_interaction.rds")

# Run interaction models for all lag intervals in parallel
results_interaction <- future_map2(
    datasets, files_interaction,
    ~fit_brm(interaction_formula, data = .x, file = .y),
    .options = furrr_options(seed = TRUE),
    .progress = TRUE
)

# Assign to individual objects
names(results_interaction) <- paste0("brm_", names(datasets), "_interaction")
list2env(results_interaction, envir = .GlobalEnv)

cat("Interaction models complete!\n")
```

## Model Comparison and Results

```{r model-comparison}
cat("\n=== ALL MODELS COMPLETE ===\n")

model_files <- c(
    "30-minute lag models:",
    "  - brm_30m_base.rds",
    "  - brm_30m_wind.rds",
    "  - brm_30m_temp.rds",
    "  - brm_30m_additive.rds",
    "  - brm_30m_interaction.rds",
    "",
    "2-hour lag models:",
    "  - brm_120m_base.rds",
    "  - brm_120m_wind.rds",
    "  - brm_120m_temp.rds",
    "  - brm_120m_additive.rds",
    "  - brm_120m_interaction.rds",
    "",
    "4-hour lag models:",
    "  - brm_240m_base.rds",
    "  - brm_240m_wind.rds",
    "  - brm_240m_temp.rds",
    "  - brm_240m_additive.rds",
    "  - brm_240m_interaction.rds"
)

cat(paste(model_files, collapse = "\n"))

# Example: quick diagnostics you can expand as needed
# print(summary(brm_30m_additive))
# bayesplot::mcmc_neff(neff_ratio(brm_30m_additive))
# loo::loo(brm_30m_additive, brm_30m_interaction)

cat("\n\nNext steps:\n")
cat("1) Check convergence: summary(), rhat(), neff_ratio()\n")
cat("2) Compare models: loo() or add_criterion('loo')\n")
cat("3) Posterior predictive checks: pp_check()\n")
```

## Session Information

```{r session-info}
sessionInfo()
