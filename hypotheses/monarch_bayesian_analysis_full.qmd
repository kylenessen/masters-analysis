---
title: "Monarch Butterfly Abundance: Full Bayesian GAM Analysis"
author: "Analysis Report"
date: "`r Sys.Date()`"
format: html
---

# Monarch Butterfly Abundance: Bayesian GAM Analysis Across Multiple Time Lags

This document fits Bayesian GAM models across 30-minute, 2-hour, and 4-hour time lags to understand how environmental factors influence monarch butterfly abundance.

## Setup and Data Loading

```{r setup, message=FALSE, warning=FALSE}
library(brms)
library(tidyverse)
library(lubridate)
library(knitr)
library(bayesplot)
library(data.table) # high-performance joins/aggregations
library(future)      # parallel processing
library(furrr)       # parallel purrr functions

# Use CmdStanR backend for performance
options(brms.backend = "cmdstanr")

# Setup parallel processing for 24-core machine
# Reserve 4 cores per model, allowing 5 models to run simultaneously
# Keep some cores free for system processes
plan(multisession, workers = 20)  # Use 20 cores total

cat("Bayesian GAM Analysis Setup Complete\n")
cat("Backend:", getOption("brms.backend"), "\n")
cat("Parallel workers:", nbrOfWorkers(), "\n")
```

```{r load-data, message=FALSE}
# Load raw data
counts <- readr::read_csv("../data/butterfly_abundance_index.csv", show_col_types = FALSE)
deployments <- readr::read_csv("../data/deployments.csv", show_col_types = FALSE)
temp <- readr::read_csv("../data/temperature_data_2023.csv", show_col_types = FALSE)
wind <- readr::read_csv("../data/wind_all.csv", show_col_types = FALSE)

cat("Data loaded successfully\n")
cat("Counts rows:", nrow(counts), "\n")
cat("Deployments rows:", nrow(deployments), "\n")
cat("Temperature rows:", nrow(temp), "\n")
cat("Wind rows:", nrow(wind), "\n")
```

## Data Preparation

```{r data-preparation, message=FALSE}
# Filter and prepare deployments data
deployments_filtered <- deployments %>%
    filter(label_status == "Complete") %>%
    mutate(view_id = as.factor(view_id)) %>%
    select(deployment_id, view_id, wind_meter_name)

# Parse timestamps in counts data (YYYYMMDDHHMMSS in image_filename)
counts_with_datetime <- counts %>%
    mutate(
        datetime_str = stringr::str_extract(image_filename, "\\d{14}"),
        datetime     = lubridate::ymd_hms(datetime_str, tz = "UTC")
    ) %>%
    select(-datetime_str)

# Create master dataframe
master_df <- counts_with_datetime %>%
    left_join(deployments_filtered, by = "deployment_id") %>%
    left_join(temp, by = c("image_filename" = "filename"))

# Coerce critical time columns; keep wind in UTC as well
master_df <- master_df %>%
    mutate(
        view_id  = as.factor(view_id),
        datetime = as.POSIXct(datetime, tz = "UTC")
    )

# Wind table must have clear names: wind_meter_name, time, speed, gust
wind <- wind %>%
    mutate(
        time = as.POSIXct(time, tz = "UTC")
    )

cat("Master dataframe created with", nrow(master_df), "rows\n")
```

## Super-fast lag builder (vectorized, no loops)

```{r lag-function, message=FALSE}
# This version uses data.table non-equi joins to aggregate over [t-Î”, t] intervals
# per (view_id, wind_meter_name). It replaces the slow R loop.

prepare_lag_data <- function(master_df, wind_df, lag_minutes) {
    cat("Preparing data for", lag_minutes, "minute lag...\n")

    # Ensure unique column names in wind_df
    wind_df <- wind_df %>% rename(wind_time = time)

    df_t <- master_df %>%
        filter(!is.na(datetime) & !is.na(view_id))

    df_t_lag <- df_t %>%
        rename(
            abundance_t_minus_1        = total_butterflies,
            datetime_t_minus_1         = datetime,
            butterflies_sun_t_minus_1  = butterflies_direct_sun,
            temperature_t_minus_1      = temperature
        ) %>%
        mutate(datetime_expected = datetime_t_minus_1 + minutes(lag_minutes)) %>%
        select(
            view_id, datetime_t_minus_1, datetime_expected,
            abundance_t_minus_1, butterflies_sun_t_minus_1, temperature_t_minus_1
        )

    final_df <- df_t %>%
        left_join(
            df_t_lag,
            by = c("view_id" = "view_id", "datetime" = "datetime_expected")
        ) %>%
        filter(!is.na(abundance_t_minus_1)) %>%
        filter(!(total_butterflies == 0 & abundance_t_minus_1 == 0)) %>%
        mutate(
            time_delta_mins = as.numeric(difftime(datetime, datetime_t_minus_1, units = "mins"))
        )

    cat("Valid pairs after filtering:", nrow(final_df), "\n")
    if (nrow(final_df) == 0) {
        return(final_df[0, ])
    }

    intervals <- final_df %>%
        select(view_id, wind_meter_name, datetime_t_minus_1, datetime) %>%
        distinct() %>%
        mutate(interval_id = dplyr::row_number())

    wind_dt <- as.data.table(wind_df)
    master_dt <- as.data.table(master_df)
    ints_dt <- as.data.table(intervals)

    setkey(wind_dt, wind_meter_name, wind_time)
    setkey(master_dt, view_id, datetime)

    # Now use wind_time in non-equi join (remove duplicate wind_time from join)
    wind_ag <- wind_dt[
        ints_dt,
        on = .(
            wind_meter_name,
            wind_time >= datetime_t_minus_1,
            wind_time <= datetime
        ),
        allow.cartesian = TRUE,
        nomatch = 0L
    ][, .(
        interval_id        = interval_id[1L],
        mean_wind_speed    = mean(speed, na.rm = TRUE),
        max_wind_speed     = suppressWarnings(max(speed, na.rm = TRUE)),
        sd_wind_speed      = sd(speed, na.rm = TRUE),
        gust_factor        = mean(gust, na.rm = TRUE) / mean(speed, na.rm = TRUE),
        minutes_above_2mps = sum(speed > 2, na.rm = TRUE)
    ), by = .(wind_meter_name, interval_id)]


    # Guard against all-NA => max = -Inf
    if (nrow(wind_ag)) {
        wind_ag[, max_wind_speed := ifelse(is.finite(max_wind_speed), max_wind_speed, NA_real_)]
        wind_ag[, gust_factor := ifelse(is.finite(gust_factor), gust_factor, NA_real_)]
    }

    # TEMPERATURE & SUNLIGHT metrics over [start, end]
    master_ag <- master_dt[
        ints_dt,
        on = .(
            view_id,
            datetime >= datetime_t_minus_1,
            datetime <= datetime
        ),
        allow.cartesian = TRUE,
        nomatch = 0L
    ][, {
        props <- ifelse(total_butterflies > 0,
            butterflies_direct_sun / total_butterflies,
            NA_real_
        )
        sum_total <- sum(total_butterflies, na.rm = TRUE)
        sum_sun <- sum(butterflies_direct_sun, na.rm = TRUE)
        sunlight_prop <- if (sum_total > 0) sum_sun / sum_total else NA_real_

        pmax <- suppressWarnings(max(props, na.rm = TRUE))
        pmin <- suppressWarnings(min(props, na.rm = TRUE))
        psd <- sd(props, na.rm = TRUE)
        pmax <- ifelse(is.finite(pmax), pmax, NA_real_)
        pmin <- ifelse(is.finite(pmin), pmin, NA_real_)
        psd <- ifelse(is.finite(psd), psd, NA_real_)

        .(
            interval_id         = interval_id[1L],
            mean_temp           = mean(temperature, na.rm = TRUE),
            max_temp            = suppressWarnings(max(temperature, na.rm = TRUE)),
            min_temp            = suppressWarnings(min(temperature, na.rm = TRUE)),
            sd_temp             = sd(temperature, na.rm = TRUE),
            sunlight_proportion = sunlight_prop,
            max_prop_sunlight   = pmax,
            min_prop_sunlight   = pmin,
            sd_prop_sunlight    = psd
        )
    }, by = .(view_id, interval_id)]

    if (nrow(master_ag)) {
        master_ag[, `:=`(
            max_temp = ifelse(is.finite(max_temp), max_temp, NA_real_),
            min_temp = ifelse(is.finite(min_temp), min_temp, NA_real_)
        )]
    }

    # Merge metrics back to the matched pairs
    # First select only unique columns from each dataset before merging
    wind_ag_clean <- wind_ag[, .(interval_id, mean_wind_speed, max_wind_speed, 
                                  sd_wind_speed, gust_factor, minutes_above_2mps)]
    master_ag_clean <- master_ag[, .(interval_id, mean_temp, max_temp, min_temp, 
                                      sd_temp, sunlight_proportion, max_prop_sunlight, 
                                      min_prop_sunlight, sd_prop_sunlight)]
    metrics <- merge(wind_ag_clean, master_ag_clean, by = "interval_id", all = TRUE)

    final_out <- final_df %>%
        left_join(intervals, by = c("view_id", "wind_meter_name", "datetime_t_minus_1", "datetime")) %>%
        left_join(metrics, by = "interval_id") %>%
        select(-interval_id) %>%
        filter(!is.na(mean_wind_speed) & !is.na(mean_temp)) %>%
        arrange(view_id, datetime)

    cat("Final dataset rows:", nrow(final_out), "\n")
    if (nrow(final_out) > 0) {
        cat(
            "Time delta range:",
            round(min(final_out$time_delta_mins, na.rm = TRUE), 1), "to",
            round(max(final_out$time_delta_mins, na.rm = TRUE), 1), "minutes\n"
        )
    }

    final_out
}
```

## Generate Lag Datasets

```{r generate-datasets}
cat("=== GENERATING LAG DATASETS ===\n")

data_30m <- prepare_lag_data(master_df, wind, lag_minutes = 30)
data_120m <- prepare_lag_data(master_df, wind, lag_minutes = 120)
data_240m <- prepare_lag_data(master_df, wind, lag_minutes = 240)

cat("\n=== DATASET SUMMARY ===\n")
cat("30-minute lag dataset:", nrow(data_30m), "observations\n")
cat("2-hour   lag dataset:", nrow(data_120m), "observations\n")
cat("4-hour   lag dataset:", nrow(data_240m), "observations\n")
```

## Bayesian Modeling Setup

```{r modeling-setup}
# ===============================================================
# SETUP
# ===============================================================

# Weakly-informative priors
my_priors <- c(
    prior(student_t(3, 0, 2.5), class = "Intercept"),
    prior(normal(0, 1), class = "sds"),
    prior(normal(0, 1), class = "ar")
)

# Parallelization plan for a 24-core machine
# Since threading is disabled with AR models, we run all chains in parallel
# With 24 cores, we could run 6 models simultaneously (4 cores each)
CHAINS <- 4 # standard for diagnostics
CORES <- 4 # run all 4 chains in parallel
# THREADS disabled due to AR terms
ITER <- 2000 # reduced for faster iteration
WARMUP <- 1000
SEED <- 20250812

ctrl <- list(adapt_delta = 0.9, max_treedepth = 12)

cat("Parallel plan (24-core machine):\n")
cat(
    "  chains =", CHAINS,
    "| cores per model =", CORES,
    "| potential parallel models =", floor(24/CORES), "\n"
)
cat("Note: With AR terms, within-chain threading is disabled\n")
cat("Consider using future/furrr to run multiple models in parallel\n")

# Helper to standardize common brms args
# Note: Threading disabled due to AR terms in models
brms_common <- list(
    family          = negbinomial(),
    prior           = my_priors,
    iter            = ITER,
    warmup          = WARMUP,
    chains          = CHAINS,
    cores           = CORES,  # Use all 4 cores for 4 chains
    # threads       = threading(THREADS), # Disabled - not supported with AR models
    seed            = SEED,
    backend         = "cmdstanr",
    control         = ctrl,
    save_pars       = save_pars(all = TRUE),
    file_refit      = "on_change" # only refit if formula/data/prior changed
)

# Convenience wrapper to splice common args safely
fit_brm <- function(formula, data, file) {
    do.call(
        what = brms::brm,
        args = c(list(
            formula = formula,
            data    = data,
            file    = file
        ), brms_common)
    )
}

# Prep function to ensure ordering/vars for AR structure
prepare_brms_data <- function(df) {
    required_vars <- c(
        "total_butterflies", "abundance_t_minus_1", "mean_wind_speed",
        "mean_temp", "sunlight_proportion", "view_id", "datetime"
    )
    missing_vars <- setdiff(required_vars, names(df))
    if (length(missing_vars) > 0) {
        stop("Missing required variables: ", paste(missing_vars, collapse = ", "))
    }
    df %>%
        select(all_of(required_vars)) %>%
        tidyr::drop_na() %>%
        arrange(view_id, datetime)
}

# Prepare the datasets for modeling
cat("Preparing datasets for brms modeling...\n")
data_30m_brms <- prepare_brms_data(data_30m)
data_120m_brms <- prepare_brms_data(data_120m)
data_240m_brms <- prepare_brms_data(data_240m)

cat("\n=== BRMS-READY DATASETS ===\n")
cat("30-minute:", nrow(data_30m_brms), "observations\n")
cat("2-hour:   ", nrow(data_120m_brms), "observations\n")
cat("4-hour:   ", nrow(data_240m_brms), "observations\n")
```

## Model Fitting

### Option: Run All Models Simultaneously

```{r run-all-models-option, eval=FALSE}
# OPTIONAL: Run all 15 models at once (requires sufficient memory)
# This would use 15 * 4 = 60 cores, so we'll stick with sequential batches
# But if you have sufficient RAM and want maximum speed, you could:
# plan(multisession, workers = 15)  # Then set cores = 1 in brms_common
```

### 30-Minute Lag Models

```{r models-30min}
cat("\nStarting 30-Minute Lag Models (Parallel Execution)...\n")

# Define model specifications
models_30m <- list(
    base = bf(total_butterflies ~ s(abundance_t_minus_1, k = 20) +
              (1 | view_id) +
              ar(time = datetime, gr = view_id, p = 1)),
    
    wind = bf(total_butterflies ~ s(abundance_t_minus_1, k = 20) +
              s(mean_wind_speed) +
              (1 | view_id) +
              ar(time = datetime, gr = view_id, p = 1)),
    
    temp = bf(total_butterflies ~ s(abundance_t_minus_1, k = 20) +
              s(mean_temp) +
              (1 | view_id) +
              ar(time = datetime, gr = view_id, p = 1)),
    
    additive = bf(total_butterflies ~ s(abundance_t_minus_1, k = 20) +
                  s(mean_wind_speed) +
                  s(mean_temp) +
                  s(sunlight_proportion) +
                  (1 | view_id) +
                  ar(time = datetime, gr = view_id, p = 1)),
    
    interaction = bf(total_butterflies ~ s(abundance_t_minus_1, k = 20) +
                     s(mean_wind_speed) +
                     t2(mean_temp, sunlight_proportion) +
                     (1 | view_id) +
                     ar(time = datetime, gr = view_id, p = 1))
)

# File names for caching
files_30m <- paste0("brm_30m_", names(models_30m), ".rds")

# Run all models in parallel
cat("Fitting", length(models_30m), "models in parallel...\n")
results_30m <- future_map2(
    models_30m, files_30m,
    ~fit_brm(.x, data = data_30m_brms, file = .y),
    .options = furrr_options(seed = TRUE),
    .progress = TRUE
)

# Assign to individual objects for backward compatibility
names(results_30m) <- paste0("brm_30m_", names(models_30m))
list2env(results_30m, envir = .GlobalEnv)

cat("30-minute lag models complete!\n")
```

### 2-Hour Lag Models

```{r models-120min}
cat("\nStarting 2-Hour Lag Models (Parallel Execution)...\n")

# Define model specifications (same structure, different data)
models_120m <- list(
    base = bf(total_butterflies ~ s(abundance_t_minus_1, k = 20) +
              (1 | view_id) +
              ar(time = datetime, gr = view_id, p = 1)),
    
    wind = bf(total_butterflies ~ s(abundance_t_minus_1, k = 20) +
              s(mean_wind_speed) +
              (1 | view_id) +
              ar(time = datetime, gr = view_id, p = 1)),
    
    temp = bf(total_butterflies ~ s(abundance_t_minus_1, k = 20) +
              s(mean_temp) +
              (1 | view_id) +
              ar(time = datetime, gr = view_id, p = 1)),
    
    additive = bf(total_butterflies ~ s(abundance_t_minus_1, k = 20) +
                  s(mean_wind_speed) +
                  s(mean_temp) +
                  s(sunlight_proportion) +
                  (1 | view_id) +
                  ar(time = datetime, gr = view_id, p = 1)),
    
    interaction = bf(total_butterflies ~ s(abundance_t_minus_1, k = 20) +
                     s(mean_wind_speed) +
                     t2(mean_temp, sunlight_proportion) +
                     (1 | view_id) +
                     ar(time = datetime, gr = view_id, p = 1))
)

# File names for caching
files_120m <- paste0("brm_120m_", names(models_120m), ".rds")

# Run all models in parallel
cat("Fitting", length(models_120m), "models in parallel...\n")
results_120m <- future_map2(
    models_120m, files_120m,
    ~fit_brm(.x, data = data_120m_brms, file = .y),
    .options = furrr_options(seed = TRUE),
    .progress = TRUE
)

# Assign to individual objects for backward compatibility
names(results_120m) <- paste0("brm_120m_", names(models_120m))
list2env(results_120m, envir = .GlobalEnv)

cat("2-hour lag models complete!\n")
```

### 4-Hour Lag Models

```{r models-240min}
cat("\nStarting 4-Hour Lag Models (Parallel Execution)...\n")

# Define model specifications (same structure, different data)
models_240m <- list(
    base = bf(total_butterflies ~ s(abundance_t_minus_1, k = 20) +
              (1 | view_id) +
              ar(time = datetime, gr = view_id, p = 1)),
    
    wind = bf(total_butterflies ~ s(abundance_t_minus_1, k = 20) +
              s(mean_wind_speed) +
              (1 | view_id) +
              ar(time = datetime, gr = view_id, p = 1)),
    
    temp = bf(total_butterflies ~ s(abundance_t_minus_1, k = 20) +
              s(mean_temp) +
              (1 | view_id) +
              ar(time = datetime, gr = view_id, p = 1)),
    
    additive = bf(total_butterflies ~ s(abundance_t_minus_1, k = 20) +
                  s(mean_wind_speed) +
                  s(mean_temp) +
                  s(sunlight_proportion) +
                  (1 | view_id) +
                  ar(time = datetime, gr = view_id, p = 1)),
    
    interaction = bf(total_butterflies ~ s(abundance_t_minus_1, k = 20) +
                     s(mean_wind_speed) +
                     t2(mean_temp, sunlight_proportion) +
                     (1 | view_id) +
                     ar(time = datetime, gr = view_id, p = 1))
)

# File names for caching
files_240m <- paste0("brm_240m_", names(models_240m), ".rds")

# Run all models in parallel
cat("Fitting", length(models_240m), "models in parallel...\n")
results_240m <- future_map2(
    models_240m, files_240m,
    ~fit_brm(.x, data = data_240m_brms, file = .y),
    .options = furrr_options(seed = TRUE),
    .progress = TRUE
)

# Assign to individual objects for backward compatibility
names(results_240m) <- paste0("brm_240m_", names(models_240m))
list2env(results_240m, envir = .GlobalEnv)

cat("4-hour lag models complete!\n")
```

## Model Comparison and Results

```{r model-comparison}
cat("\n=== ALL MODELS COMPLETE ===\n")

model_files <- c(
    "30-minute lag models:",
    "  - brm_30m_base.rds",
    "  - brm_30m_wind.rds",
    "  - brm_30m_temp.rds",
    "  - brm_30m_additive.rds",
    "  - brm_30m_interaction.rds",
    "",
    "2-hour lag models:",
    "  - brm_120m_base.rds",
    "  - brm_120m_wind.rds",
    "  - brm_120m_temp.rds",
    "  - brm_120m_additive.rds",
    "  - brm_120m_interaction.rds",
    "",
    "4-hour lag models:",
    "  - brm_240m_base.rds",
    "  - brm_240m_wind.rds",
    "  - brm_240m_temp.rds",
    "  - brm_240m_additive.rds",
    "  - brm_240m_interaction.rds"
)

cat(paste(model_files, collapse = "\n"))

# Example: quick diagnostics you can expand as needed
# print(summary(brm_30m_additive))
# bayesplot::mcmc_neff(neff_ratio(brm_30m_additive))
# loo::loo(brm_30m_additive, brm_30m_interaction)

cat("\n\nNext steps:\n")
cat("1) Check convergence: summary(), rhat(), neff_ratio()\n")
cat("2) Compare models: loo() or add_criterion('loo')\n")
cat("3) Posterior predictive checks: pp_check()\n")
```

## Session Information

```{r session-info}
sessionInfo()
