---
title: "Monarch Butterfly Abundance: Full Bayesian GAM Analysis"
author: "Analysis Report"
date: "`r Sys.Date()`"
format: html
---

# Monarch Butterfly Abundance: Bayesian GAM Analysis Across Multiple Time Lags

This document fits Bayesian GAM models across 30-minute, 2-hour, and 4-hour time lags to understand how environmental factors influence monarch butterfly abundance.

## Setup and Data Loading

```{r setup, message=FALSE, warning=FALSE}
library(brms)
library(tidyverse)
library(lubridate)
library(knitr)
library(kableExtra)  # for nice tables
library(bayesplot)
library(data.table) # high-performance joins/aggregations
library(future)      # parallel processing
library(furrr)       # parallel purrr functions
library(gridExtra)   # for arranging plots

# Use CmdStanR backend for performance
options(brms.backend = "cmdstanr")

# Setup parallel processing for 24-core machine
# Running 3 models at a time (same model type across lag intervals)
# This uses 3 × 4 = 12 cores, leaving plenty of headroom
plan(multisession, workers = 12)  # Use 12 cores total

cat("Bayesian GAM Analysis Setup Complete\n")
cat("Backend:", getOption("brms.backend"), "\n")
cat("Parallel workers:", nbrOfWorkers(), "\n")
```

```{r load-data, message=FALSE}
# Load raw data
counts <- readr::read_csv("../data/butterfly_abundance_index.csv", show_col_types = FALSE)
deployments <- readr::read_csv("../data/deployments.csv", show_col_types = FALSE)
temp <- readr::read_csv("../data/temperature_data_2023.csv", show_col_types = FALSE)
wind <- readr::read_csv("../data/wind_all.csv", show_col_types = FALSE)

cat("Data loaded successfully\n")
cat("Counts rows:", nrow(counts), "\n")
cat("Deployments rows:", nrow(deployments), "\n")
cat("Temperature rows:", nrow(temp), "\n")
cat("Wind rows:", nrow(wind), "\n")
```

## Data Preparation

```{r data-preparation, message=FALSE}
# Filter and prepare deployments data
deployments_filtered <- deployments %>%
    filter(label_status == "Complete") %>%
    mutate(view_id = as.factor(view_id)) %>%
    select(deployment_id, view_id, wind_meter_name)

# Parse timestamps in counts data (YYYYMMDDHHMMSS in image_filename)
counts_with_datetime <- counts %>%
    mutate(
        datetime_str = stringr::str_extract(image_filename, "\\d{14}"),
        datetime     = lubridate::ymd_hms(datetime_str, tz = "UTC")
    ) %>%
    select(-datetime_str)

# Create master dataframe
master_df <- counts_with_datetime %>%
    left_join(deployments_filtered, by = "deployment_id") %>%
    left_join(temp, by = c("image_filename" = "filename"))

# Coerce critical time columns; keep wind in UTC as well
master_df <- master_df %>%
    mutate(
        view_id  = as.factor(view_id),
        datetime = as.POSIXct(datetime, tz = "UTC")
    )

# Wind table must have clear names: wind_meter_name, time, speed, gust
wind <- wind %>%
    mutate(
        time = as.POSIXct(time, tz = "UTC")
    )

cat("Master dataframe created with", nrow(master_df), "rows\n")
```

## Super-fast lag builder (vectorized, no loops)

```{r lag-function, message=FALSE}
# This version uses data.table non-equi joins to aggregate over [t-Δ, t] intervals
# per (view_id, wind_meter_name). It replaces the slow R loop.

prepare_lag_data <- function(master_df, wind_df, lag_minutes) {
    cat("Preparing data for", lag_minutes, "minute lag...\n")

    # Ensure unique column names in wind_df
    wind_df <- wind_df %>% rename(wind_time = time)

    df_t <- master_df %>%
        filter(!is.na(datetime) & !is.na(view_id))

    df_t_lag <- df_t %>%
        rename(
            abundance_t_minus_1        = total_butterflies,
            datetime_t_minus_1         = datetime,
            butterflies_sun_t_minus_1  = butterflies_direct_sun,
            temperature_t_minus_1      = temperature
        ) %>%
        mutate(datetime_expected = datetime_t_minus_1 + minutes(lag_minutes)) %>%
        select(
            view_id, datetime_t_minus_1, datetime_expected,
            abundance_t_minus_1, butterflies_sun_t_minus_1, temperature_t_minus_1
        )

    final_df <- df_t %>%
        left_join(
            df_t_lag,
            by = c("view_id" = "view_id", "datetime" = "datetime_expected")
        ) %>%
        filter(!is.na(abundance_t_minus_1)) %>%
        filter(!(total_butterflies == 0 & abundance_t_minus_1 == 0)) %>%
        mutate(
            time_delta_mins = as.numeric(difftime(datetime, datetime_t_minus_1, units = "mins"))
        )

    cat("Valid pairs after filtering:", nrow(final_df), "\n")
    if (nrow(final_df) == 0) {
        return(final_df[0, ])
    }

    intervals <- final_df %>%
        select(view_id, wind_meter_name, datetime_t_minus_1, datetime) %>%
        distinct() %>%
        mutate(interval_id = dplyr::row_number())

    wind_dt <- as.data.table(wind_df)
    master_dt <- as.data.table(master_df)
    ints_dt <- as.data.table(intervals)

    setkey(wind_dt, wind_meter_name, wind_time)
    setkey(master_dt, view_id, datetime)

    # Now use wind_time in non-equi join (remove duplicate wind_time from join)
    wind_ag <- wind_dt[
        ints_dt,
        on = .(
            wind_meter_name,
            wind_time >= datetime_t_minus_1,
            wind_time <= datetime
        ),
        allow.cartesian = TRUE,
        nomatch = 0L
    ][, .(
        interval_id        = interval_id[1L],
        mean_wind_speed    = mean(speed, na.rm = TRUE),
        max_wind_speed     = suppressWarnings(max(speed, na.rm = TRUE)),
        sd_wind_speed      = sd(speed, na.rm = TRUE),
        gust_factor        = mean(gust, na.rm = TRUE) / mean(speed, na.rm = TRUE),
        minutes_above_2mps = sum(speed > 2, na.rm = TRUE)
    ), by = .(wind_meter_name, interval_id)]


    # Guard against all-NA => max = -Inf
    if (nrow(wind_ag)) {
        wind_ag[, max_wind_speed := ifelse(is.finite(max_wind_speed), max_wind_speed, NA_real_)]
        wind_ag[, gust_factor := ifelse(is.finite(gust_factor), gust_factor, NA_real_)]
    }

    # TEMPERATURE & SUNLIGHT metrics over [start, end]
    master_ag <- master_dt[
        ints_dt,
        on = .(
            view_id,
            datetime >= datetime_t_minus_1,
            datetime <= datetime
        ),
        allow.cartesian = TRUE,
        nomatch = 0L
    ][, {
        props <- ifelse(total_butterflies > 0,
            butterflies_direct_sun / total_butterflies,
            NA_real_
        )
        sum_total <- sum(total_butterflies, na.rm = TRUE)
        sum_sun <- sum(butterflies_direct_sun, na.rm = TRUE)
        sunlight_prop <- if (sum_total > 0) sum_sun / sum_total else NA_real_

        pmax <- suppressWarnings(max(props, na.rm = TRUE))
        pmin <- suppressWarnings(min(props, na.rm = TRUE))
        psd <- sd(props, na.rm = TRUE)
        pmax <- ifelse(is.finite(pmax), pmax, NA_real_)
        pmin <- ifelse(is.finite(pmin), pmin, NA_real_)
        psd <- ifelse(is.finite(psd), psd, NA_real_)

        .(
            interval_id         = interval_id[1L],
            mean_temp           = mean(temperature, na.rm = TRUE),
            max_temp            = suppressWarnings(max(temperature, na.rm = TRUE)),
            min_temp            = suppressWarnings(min(temperature, na.rm = TRUE)),
            sd_temp             = sd(temperature, na.rm = TRUE),
            sunlight_proportion = sunlight_prop,
            max_prop_sunlight   = pmax,
            min_prop_sunlight   = pmin,
            sd_prop_sunlight    = psd
        )
    }, by = .(view_id, interval_id)]

    if (nrow(master_ag)) {
        master_ag[, `:=`(
            max_temp = ifelse(is.finite(max_temp), max_temp, NA_real_),
            min_temp = ifelse(is.finite(min_temp), min_temp, NA_real_)
        )]
    }

    # Merge metrics back to the matched pairs
    # First select only unique columns from each dataset before merging
    wind_ag_clean <- wind_ag[, .(interval_id, mean_wind_speed, max_wind_speed, 
                                  sd_wind_speed, gust_factor, minutes_above_2mps)]
    master_ag_clean <- master_ag[, .(interval_id, mean_temp, max_temp, min_temp, 
                                      sd_temp, sunlight_proportion, max_prop_sunlight, 
                                      min_prop_sunlight, sd_prop_sunlight)]
    metrics <- merge(wind_ag_clean, master_ag_clean, by = "interval_id", all = TRUE)

    final_out <- final_df %>%
        left_join(intervals, by = c("view_id", "wind_meter_name", "datetime_t_minus_1", "datetime")) %>%
        left_join(metrics, by = "interval_id") %>%
        select(-interval_id) %>%
        filter(!is.na(mean_wind_speed) & !is.na(mean_temp)) %>%
        arrange(view_id, datetime)

    cat("Final dataset rows:", nrow(final_out), "\n")
    if (nrow(final_out) > 0) {
        cat(
            "Time delta range:",
            round(min(final_out$time_delta_mins, na.rm = TRUE), 1), "to",
            round(max(final_out$time_delta_mins, na.rm = TRUE), 1), "minutes\n"
        )
    }

    final_out
}
```

## Generate Lag Datasets

```{r generate-datasets}
cat("=== GENERATING LAG DATASETS ===\n")

data_30m <- prepare_lag_data(master_df, wind, lag_minutes = 30)
data_120m <- prepare_lag_data(master_df, wind, lag_minutes = 120)
data_240m <- prepare_lag_data(master_df, wind, lag_minutes = 240)

cat("\n=== DATASET SUMMARY ===\n")
cat("30-minute lag dataset:", nrow(data_30m), "observations\n")
cat("2-hour   lag dataset:", nrow(data_120m), "observations\n")
cat("4-hour   lag dataset:", nrow(data_240m), "observations\n")
```

## Bayesian Modeling Setup

```{r modeling-setup}
# ===============================================================
# SETUP
# ===============================================================

# SAMPLING OPTION: Set to TRUE for testing, FALSE for full analysis
USE_SAMPLE <- TRUE
SAMPLE_SIZE <- 300

# More informative priors to help with convergence
my_priors <- c(
    prior(student_t(3, 0, 2.5), class = "Intercept"),
    prior(normal(0, 0.5), class = "sds"),  # Tighter prior on smooth terms
    prior(normal(0.5, 0.3), class = "ar"),  # Expect positive autocorrelation
    prior(exponential(1), class = "shape")  # Prior for negative binomial dispersion
)

# Parallelization plan for a 24-core machine
# Since threading is disabled with AR models, we run all chains in parallel
# With 24 cores, we could run 6 models simultaneously (4 cores each)
CHAINS <- 4 # standard for diagnostics
CORES <- 4 # run all 4 chains in parallel
# THREADS disabled due to AR terms

# Adjust iterations based on whether we're testing or running full analysis
if (USE_SAMPLE) {
    ITER <- 2000   # Increased for better sampling
    WARMUP <- 1000  # Increased warmup for better adaptation
    cat("Using testing iterations: ITER =", ITER, ", WARMUP =", WARMUP, "\n")
} else {
    ITER <- 4000   # Full analysis
    WARMUP <- 2000 # Increased warmup for full analysis
}

SEED <- 20250812

# Updated control parameters to address divergences and E-BFMI warnings
ctrl <- list(
    adapt_delta = 0.95,     # Increased from 0.9 to reduce divergences
    max_treedepth = 15,     # Increased from 12 for complex posteriors
    stepsize = 0.01         # Smaller stepsize for better exploration
)

cat("Parallel plan (24-core machine):\n")
cat(
    "  chains =", CHAINS,
    "| cores per model =", CORES,
    "| potential parallel models =", floor(24/CORES), "\n"
)
cat("Note: With AR terms, within-chain threading is disabled\n")
cat("Consider using future/furrr to run multiple models in parallel\n")

# Helper to standardize common brms args
# Note: Threading disabled due to AR terms in models
brms_common <- list(
    family          = negbinomial(),
    prior           = my_priors,
    iter            = ITER,
    warmup          = WARMUP,
    chains          = CHAINS,
    cores           = CORES,  # Use all 4 cores for 4 chains
    # threads       = threading(THREADS), # Disabled - not supported with AR models
    seed            = SEED,
    backend         = "cmdstanr",
    control         = ctrl,
    save_pars       = save_pars(all = TRUE),
    file_refit      = "on_change" # only refit if formula/data/prior changed
)

# Convenience wrapper to splice common args safely
fit_brm <- function(formula, data, file) {
    do.call(
        what = brms::brm,
        args = c(list(
            formula = formula,
            data    = data,
            file    = file
        ), brms_common)
    )
}

# Prep function to ensure ordering/vars for AR structure
prepare_brms_data <- function(df) {
    required_vars <- c(
        "total_butterflies", "abundance_t_minus_1", "mean_wind_speed",
        "mean_temp", "sunlight_proportion", "view_id", "datetime"
    )
    missing_vars <- setdiff(required_vars, names(df))
    if (length(missing_vars) > 0) {
        stop("Missing required variables: ", paste(missing_vars, collapse = ", "))
    }
    df %>%
        select(all_of(required_vars)) %>%
        tidyr::drop_na() %>%
        arrange(view_id, datetime)
}

# Prepare the datasets for modeling
cat("Preparing datasets for brms modeling...\n")

if (USE_SAMPLE) {
    cat("\n*** USING SAMPLED DATA FOR TESTING ***\n")
    cat("Sample size:", SAMPLE_SIZE, "observations per dataset\n\n")
    
    set.seed(SEED)  # Ensure reproducible sampling
    
    # Sample from each dataset
    data_30m_brms <- prepare_brms_data(data_30m) %>%
        sample_n(min(SAMPLE_SIZE, n()))
    
    data_120m_brms <- prepare_brms_data(data_120m) %>%
        sample_n(min(SAMPLE_SIZE, n()))
    
    data_240m_brms <- prepare_brms_data(data_240m) %>%
        sample_n(min(SAMPLE_SIZE, n()))
} else {
    cat("\n*** USING FULL DATA ***\n")
    data_30m_brms <- prepare_brms_data(data_30m)
    data_120m_brms <- prepare_brms_data(data_120m)
    data_240m_brms <- prepare_brms_data(data_240m)
}

cat("\n=== BRMS-READY DATASETS ===\n")
cat("30-minute:", nrow(data_30m_brms), "observations\n")
cat("2-hour:   ", nrow(data_120m_brms), "observations\n")
cat("4-hour:   ", nrow(data_240m_brms), "observations\n")
```

## Model Fitting

### Model Fitting Strategy

We'll run the same model type across all three lag intervals simultaneously.
This allows for better comparison and uses 3 models × 4 cores = 12 cores at a time,
leaving headroom for system processes.

### Baseline Models (All Lag Intervals)

```{r models-baseline}
cat("\n=== FITTING BASELINE MODELS ACROSS ALL LAG INTERVALS ===\n")
cat("Running 3 models in parallel (30min, 2hr, 4hr)...\n\n")

# Define baseline model formula
# Reduced k from 20 to 10 for smoother splines and better convergence
baseline_formula <- bf(total_butterflies ~ s(abundance_t_minus_1, k = 10) +
                       (1 | view_id) +
                       ar(time = datetime, gr = view_id, p = 1))

# Prepare data and file names
file_prefix <- if (USE_SAMPLE) "sample_" else ""
datasets <- list(
    "30m" = data_30m_brms,
    "120m" = data_120m_brms,
    "240m" = data_240m_brms
)
files_baseline <- paste0(file_prefix, "brm_", names(datasets), "_base.rds")

# Run baseline models for all lag intervals in parallel
results_baseline <- future_map2(
    datasets, files_baseline,
    ~fit_brm(baseline_formula, data = .x, file = .y),
    .options = furrr_options(seed = TRUE),
    .progress = TRUE
)

# Assign to individual objects
names(results_baseline) <- paste0("brm_", names(datasets), "_base")
list2env(results_baseline, envir = .GlobalEnv)

cat("Baseline models complete!\n")
```

### Wind Models (All Lag Intervals)

```{r models-wind}
cat("\n=== FITTING WIND MODELS ACROSS ALL LAG INTERVALS ===\n")
cat("Running 3 models in parallel (30min, 2hr, 4hr)...\n\n")

# Define wind model formula
wind_formula <- bf(total_butterflies ~ s(abundance_t_minus_1, k = 10) +
                   s(mean_wind_speed, k = 10) +
                   (1 | view_id) +
                   ar(time = datetime, gr = view_id, p = 1))

files_wind <- paste0(file_prefix, "brm_", names(datasets), "_wind.rds")

# Run wind models for all lag intervals in parallel
results_wind <- future_map2(
    datasets, files_wind,
    ~fit_brm(wind_formula, data = .x, file = .y),
    .options = furrr_options(seed = TRUE),
    .progress = TRUE
)

# Assign to individual objects
names(results_wind) <- paste0("brm_", names(datasets), "_wind")
list2env(results_wind, envir = .GlobalEnv)

cat("Wind models complete!\n")
```

### Temperature Models (All Lag Intervals)

```{r models-temp}
cat("\n=== FITTING TEMPERATURE MODELS ACROSS ALL LAG INTERVALS ===\n")
cat("Running 3 models in parallel (30min, 2hr, 4hr)...\n\n")

# Define temperature model formula
temp_formula <- bf(total_butterflies ~ s(abundance_t_minus_1, k = 10) +
                   s(mean_temp, k = 10) +
                   (1 | view_id) +
                   ar(time = datetime, gr = view_id, p = 1))

files_temp <- paste0(file_prefix, "brm_", names(datasets), "_temp.rds")

# Run temperature models for all lag intervals in parallel
results_temp <- future_map2(
    datasets, files_temp,
    ~fit_brm(temp_formula, data = .x, file = .y),
    .options = furrr_options(seed = TRUE),
    .progress = TRUE
)

# Assign to individual objects
names(results_temp) <- paste0("brm_", names(datasets), "_temp")
list2env(results_temp, envir = .GlobalEnv)

cat("Temperature models complete!\n")
```

### Additive Models (All Lag Intervals)

```{r models-additive}
cat("\n=== FITTING ADDITIVE MODELS ACROSS ALL LAG INTERVALS ===\n")
cat("Running 3 models in parallel (30min, 2hr, 4hr)...\n\n")

# Define additive model formula
additive_formula <- bf(total_butterflies ~ s(abundance_t_minus_1, k = 10) +
                       s(mean_wind_speed, k = 10) +
                       s(mean_temp, k = 10) +
                       s(sunlight_proportion, k = 10) +
                       (1 | view_id) +
                       ar(time = datetime, gr = view_id, p = 1))

files_additive <- paste0(file_prefix, "brm_", names(datasets), "_additive.rds")

# Run additive models for all lag intervals in parallel
results_additive <- future_map2(
    datasets, files_additive,
    ~fit_brm(additive_formula, data = .x, file = .y),
    .options = furrr_options(seed = TRUE),
    .progress = TRUE
)

# Assign to individual objects
names(results_additive) <- paste0("brm_", names(datasets), "_additive")
list2env(results_additive, envir = .GlobalEnv)

cat("Additive models complete!\n")
```

### Interaction Models (All Lag Intervals)

```{r models-interaction}
cat("\n=== FITTING INTERACTION MODELS ACROSS ALL LAG INTERVALS ===\n")
cat("Running 3 models in parallel (30min, 2hr, 4hr)...\n\n")

# Define interaction model formula
interaction_formula <- bf(total_butterflies ~ s(abundance_t_minus_1, k = 10) +
                          s(mean_wind_speed, k = 10) +
                          t2(mean_temp, sunlight_proportion, k = c(5, 5)) +
                          (1 | view_id) +
                          ar(time = datetime, gr = view_id, p = 1))

files_interaction <- paste0(file_prefix, "brm_", names(datasets), "_interaction.rds")

# Run interaction models for all lag intervals in parallel
results_interaction <- future_map2(
    datasets, files_interaction,
    ~fit_brm(interaction_formula, data = .x, file = .y),
    .options = furrr_options(seed = TRUE),
    .progress = TRUE
)

# Assign to individual objects
names(results_interaction) <- paste0("brm_", names(datasets), "_interaction")
list2env(results_interaction, envir = .GlobalEnv)

cat("Interaction models complete!\n")
```

## Model Comparison and Results

### Model Convergence Diagnostics

```{r convergence-checks}
cat("\n=== CONVERGENCE DIAGNOSTICS ===\n\n")

# Collect all models
all_models <- list(
    "30m_base" = brm_30m_base,
    "30m_wind" = brm_30m_wind,
    "30m_temp" = brm_30m_temp,
    "30m_additive" = brm_30m_additive,
    "30m_interaction" = brm_30m_interaction,
    "120m_base" = brm_120m_base,
    "120m_wind" = brm_120m_wind,
    "120m_temp" = brm_120m_temp,
    "120m_additive" = brm_120m_additive,
    "120m_interaction" = brm_120m_interaction,
    "240m_base" = brm_240m_base,
    "240m_wind" = brm_240m_wind,
    "240m_temp" = brm_240m_temp,
    "240m_additive" = brm_240m_additive,
    "240m_interaction" = brm_240m_interaction
)

# Check convergence for each model
convergence_summary <- data.frame(
    Model = names(all_models),
    Max_Rhat = NA,
    Min_ESS_Bulk = NA,
    Min_ESS_Tail = NA,
    Divergences = NA,
    Max_Treedepth = NA,
    E_BFMI = NA
)

for (i in seq_along(all_models)) {
    model <- all_models[[i]]
    
    # Get diagnostics
    rhats <- rhat(model)
    ess_bulk <- ess_bulk(model)
    ess_tail <- ess_tail(model)
    
    # Get sampler diagnostics
    np <- nuts_params(model)
    divergences <- sum(subset(np, Parameter == "divergent__")$Value)
    max_td <- sum(subset(np, Parameter == "treedepth__")$Value >= 
                  model$fit@stan_args[[1]]$control$max_treedepth)
    
    # Energy diagnostic
    energy <- subset(np, Parameter == "energy__")$Value
    ebfmi <- rep(NA, 4)  # for 4 chains
    for (chain in 1:4) {
        chain_energy <- energy[np$Chain == chain]
        if (length(chain_energy) > 1) {
            ebfmi[chain] <- var(diff(chain_energy)) / var(chain_energy)
        }
    }
    
    convergence_summary[i, ] <- c(
        names(all_models)[i],
        round(max(rhats, na.rm = TRUE), 3),
        round(min(ess_bulk, na.rm = TRUE), 0),
        round(min(ess_tail, na.rm = TRUE), 0),
        divergences,
        max_td,
        round(min(ebfmi, na.rm = TRUE), 3)
    )
}

# Convert numeric columns
convergence_summary[, 2:7] <- lapply(convergence_summary[, 2:7], as.numeric)

# Display convergence summary
kable(convergence_summary, 
      caption = "Convergence Diagnostics for All Models",
      format = "html") %>%
    kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))

# Flag any issues
cat("\n--- Convergence Issues ---\n")
issues <- convergence_summary %>%
    filter(Max_Rhat > 1.01 | Min_ESS_Bulk < 400 | Min_ESS_Tail < 400 | 
           Divergences > 0 | E_BFMI < 0.3)

if (nrow(issues) > 0) {
    cat("Models with potential issues:\n")
    print(issues$Model)
} else {
    cat("All models show good convergence!\n")
}
```

### Model Comparison with LOO-CV

```{r loo-comparison}
cat("\n=== LOO-CV MODEL COMPARISON ===\n\n")

# Add LOO criterion to all models
for (name in names(all_models)) {
    all_models[[name]] <- add_criterion(all_models[[name]], "loo", moment_match = TRUE)
}

# Compare models within each lag interval
cat("--- 30-Minute Lag Models ---\n")
loo_30m <- loo_compare(
    all_models$`30m_base`,
    all_models$`30m_wind`,
    all_models$`30m_temp`,
    all_models$`30m_additive`,
    all_models$`30m_interaction`
)
print(loo_30m)

cat("\n--- 2-Hour Lag Models ---\n")
loo_120m <- loo_compare(
    all_models$`120m_base`,
    all_models$`120m_wind`,
    all_models$`120m_temp`,
    all_models$`120m_additive`,
    all_models$`120m_interaction`
)
print(loo_120m)

cat("\n--- 4-Hour Lag Models ---\n")
loo_240m <- loo_compare(
    all_models$`240m_base`,
    all_models$`240m_wind`,
    all_models$`240m_temp`,
    all_models$`240m_additive`,
    all_models$`240m_interaction`
)
print(loo_240m)

# Create summary table of ELPD values
elpd_summary <- data.frame(
    Model_Type = c("Baseline", "Wind", "Temperature", "Additive", "Interaction"),
    ELPD_30m = c(
        loo(all_models$`30m_base`)$estimates["elpd_loo", "Estimate"],
        loo(all_models$`30m_wind`)$estimates["elpd_loo", "Estimate"],
        loo(all_models$`30m_temp`)$estimates["elpd_loo", "Estimate"],
        loo(all_models$`30m_additive`)$estimates["elpd_loo", "Estimate"],
        loo(all_models$`30m_interaction`)$estimates["elpd_loo", "Estimate"]
    ),
    ELPD_120m = c(
        loo(all_models$`120m_base`)$estimates["elpd_loo", "Estimate"],
        loo(all_models$`120m_wind`)$estimates["elpd_loo", "Estimate"],
        loo(all_models$`120m_temp`)$estimates["elpd_loo", "Estimate"],
        loo(all_models$`120m_additive`)$estimates["elpd_loo", "Estimate"],
        loo(all_models$`120m_interaction`)$estimates["elpd_loo", "Estimate"]
    ),
    ELPD_240m = c(
        loo(all_models$`240m_base`)$estimates["elpd_loo", "Estimate"],
        loo(all_models$`240m_wind`)$estimates["elpd_loo", "Estimate"],
        loo(all_models$`240m_temp`)$estimates["elpd_loo", "Estimate"],
        loo(all_models$`240m_additive`)$estimates["elpd_loo", "Estimate"],
        loo(all_models$`240m_interaction`)$estimates["elpd_loo", "Estimate"]
    )
)

elpd_summary[, 2:4] <- round(elpd_summary[, 2:4], 1)

cat("\n--- ELPD Summary Across Lag Intervals ---\n")
kable(elpd_summary, 
      caption = "Expected Log Predictive Density (Higher is Better)",
      format = "html") %>%
    kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

### R-squared and Model Fit Statistics

```{r model-fit-stats}
cat("\n=== MODEL FIT STATISTICS ===\n\n")

# Calculate Bayes R2 for all models
r2_summary <- data.frame(
    Model = character(),
    Lag_Interval = character(),
    Bayes_R2_Mean = numeric(),
    Bayes_R2_SD = numeric(),
    stringsAsFactors = FALSE
)

for (name in names(all_models)) {
    r2 <- bayes_R2(all_models[[name]])
    
    # Parse model name
    parts <- strsplit(name, "_")[[1]]
    lag <- parts[1]
    model_type <- parts[2]
    
    r2_summary <- rbind(r2_summary, data.frame(
        Model = model_type,
        Lag_Interval = lag,
        Bayes_R2_Mean = round(r2[1], 3),
        Bayes_R2_SD = round(r2[2], 3)
    ))
}

# Reshape for better display
r2_wide <- r2_summary %>%
    pivot_wider(
        names_from = Lag_Interval,
        values_from = c(Bayes_R2_Mean, Bayes_R2_SD),
        names_glue = "{Lag_Interval}_{.value}"
    ) %>%
    select(Model, ends_with("Mean"), ends_with("SD"))

kable(r2_wide, 
      caption = "Bayesian R-squared Values",
      format = "html") %>%
    kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

### Posterior Predictive Checks

```{r pp-checks, fig.height=10, fig.width=12}
cat("\n=== POSTERIOR PREDICTIVE CHECKS ===\n\n")

# Select best models from each lag interval for visualization
best_models <- list(
    "30m" = all_models$`30m_additive`,  # Update based on LOO results
    "120m" = all_models$`120m_additive`,
    "240m" = all_models$`240m_additive`
)

# Create posterior predictive check plots
pp_plots <- list()

for (name in names(best_models)) {
    pp_plots[[paste0(name, "_density")]] <- pp_check(best_models[[name]], 
                                                      type = "dens_overlay", 
                                                      ndraws = 50) +
        ggtitle(paste("Density Overlay -", name, "lag"))
    
    pp_plots[[paste0(name, "_scatter")]] <- pp_check(best_models[[name]], 
                                                     type = "scatter_avg") +
        ggtitle(paste("Average Predictions -", name, "lag"))
}

# Arrange plots
gridExtra::grid.arrange(grobs = pp_plots, ncol = 2)
```

### Effect Plots

```{r effect-plots, fig.height=12, fig.width=10}
cat("\n=== MARGINAL EFFECTS ===\n\n")

# Plot smooth terms for the best additive model at each lag
par(mfrow = c(3, 4))

for (lag in c("30m", "120m", "240m")) {
    model <- all_models[[paste0(lag, "_additive")]]
    plot(conditional_smooths(model), 
         ask = FALSE, 
         main = paste(lag, "Lag Interval"))
}
```

### Model Coefficients Summary

```{r coefficient-summary}
cat("\n=== KEY COEFFICIENT ESTIMATES ===\n\n")

# Extract and compare AR coefficients across models
ar_coefs <- data.frame(
    Model = character(),
    Lag = character(),
    AR_Estimate = numeric(),
    AR_Lower = numeric(),
    AR_Upper = numeric(),
    stringsAsFactors = FALSE
)

for (name in names(all_models)) {
    model <- all_models[[name]]
    post <- as_draws_df(model)
    
    # Get AR coefficient
    if ("ar[1]" %in% names(post)) {
        ar_est <- median(post$`ar[1]`)
        ar_ci <- quantile(post$`ar[1]`, c(0.025, 0.975))
        
        parts <- strsplit(name, "_")[[1]]
        
        ar_coefs <- rbind(ar_coefs, data.frame(
            Model = parts[2],
            Lag = parts[1],
            AR_Estimate = round(ar_est, 3),
            AR_Lower = round(ar_ci[1], 3),
            AR_Upper = round(ar_ci[2], 3)
        ))
    }
}

kable(ar_coefs, 
      caption = "Autoregressive (AR) Coefficient Estimates",
      format = "html") %>%
    kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

### Summary and Recommendations

```{r summary}
cat("\n=== SUMMARY ===\n\n")

# Identify best model for each lag interval
cat("Best performing models by ELPD:\n")
cat("- 30-minute lag:", rownames(loo_30m)[1], "\n")
cat("- 2-hour lag:", rownames(loo_120m)[1], "\n")
cat("- 4-hour lag:", rownames(loo_240m)[1], "\n")

cat("\n")
cat("Key findings:\n")
cat("1. Model complexity vs. fit trade-off across lag intervals\n")
cat("2. Importance of environmental predictors varies with time lag\n")
cat("3. Autocorrelation strength changes with lag interval\n")
```

## Session Information

```{r session-info}
sessionInfo()
