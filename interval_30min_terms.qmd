---
title: "30-min Interval: Term Build-Up"
format:
  html:
    toc: true
    number-sections: false
execute:
  echo: true
  warning: false
  message: false
editor: visual
---

```{r}
#| label: setup
# Load tidyverse and helpers
library(tidyverse)
library(lubridate)
library(jsonlite)
library(glmmTMB)
library(performance)
library(broom.mixed)
library(DHARMa)

# Data paths (adjust if needed)
path_abund <- "data/butterfly_abundance_index.csv"
path_deps  <- "data/deployments.csv"
path_wind  <- "data/wind_all.csv"
path_temp  <- "data/temperature_data_2023.csv"

# Toggle: should we drop intervals where t-1 == 0 and t == 0?
drop_empty_zero_intervals <- TRUE

# Ensure export dirs exist when rendering
invisible(dir.create("results", showWarnings = FALSE))
invisible(dir.create("diagnostics", showWarnings = FALSE))
```

## Step 1 — Load Abundance Index

```{r}
#| label: load-abundance
abund <- readr::read_csv(path_abund, show_col_types = FALSE) %>%
  mutate(
    timestamp = ymd_hms(timestamp, tz = "UTC", quiet = TRUE),
    # response naming convenience (we will call this abundance_index_t later)
    abundance_index = total_butterflies
  ) %>%
  arrange(deployment_id, timestamp)

# Quick glance
abund %>%
  group_by(deployment_id) %>%
  summarise(n = n(), first = min(timestamp), last = max(timestamp)) %>%
  arrange(deployment_id)
```

```{r}
#| label: check-intervals
# Verify step sizes (minutes) between consecutive images within each deployment
abund_steps <- abund %>%
  group_by(deployment_id) %>%
  arrange(timestamp, .by_group = TRUE) %>%
  mutate(
    dt_min = as.numeric(difftime(timestamp, lag(timestamp), units = "mins")),
    abundance_index_t_minus_1 = lag(abundance_index)
  ) %>%
  ungroup()

# Summarize the distribution of dt_min
abund_steps %>%
  filter(!is.na(dt_min)) %>%
  count(deployment_id, dt_min) %>%
  arrange(deployment_id, dt_min) %>%
  group_by(deployment_id) %>%
  mutate(prop = n / sum(n)) %>%
  ungroup()
```

## Step 2 — Restrict to 30-min Consecutive Pairs

```{r}
#| label: only-30min-pairs
# Keep rows where the previous image exists and the gap is exactly 30 minutes
abund_30 <- abund_steps %>%
  filter(!is.na(dt_min) & abs(dt_min - 30) < 1e-6) %>%
  mutate(
    abundance_index_t = abundance_index
  )

# Drop any rows where either t or t-1 abundance is missing
na_pair_removed <- sum(is.na(abund_30$abundance_index_t) | is.na(abund_30$abundance_index_t_minus_1))
abund_30 <- abund_30 %>% filter(!is.na(abundance_index_t) & !is.na(abundance_index_t_minus_1))

cat(sprintf("Removed %d 30-min pairs due to NA abundance at t or t-1.\n", na_pair_removed))

# Sanity check: no missing lags and correct gap
stopifnot(all(!is.na(abund_30$abundance_index_t_minus_1)))
stopifnot(all(abs(abund_30$dt_min - 30) < 1e-6))

abund_30 %>% select(deployment_id, timestamp, abundance_index_t_minus_1, abundance_index_t) %>% head(10)
```

## Step 3 — Sunlight Exposure Proportion

```{r}
#| label: sunlight-prop
# If butterflies_direct_sun is present, compute within-frame proportion
abund_30 <- abund_30 %>%
  mutate(
    sunlight_exposure_prop = case_when(
      !is.na(butterflies_direct_sun) & !is.na(total_butterflies) & total_butterflies > 0 ~
        pmin(1, pmax(0, butterflies_direct_sun / total_butterflies)),
      TRUE ~ NA_real_
    )
  )

abund_30 %>% summarise(
  n = n(),
  with_sun = sum(!is.na(sunlight_exposure_prop)),
  mean_sun = mean(sunlight_exposure_prop, na.rm = TRUE)
) 
```

## Step 4 — Ambient Temperature (mean over window)

```{r}
#| label: join-temp
# Temperature file keyed by deployment_id + per-image timestamp string
temps <- readr::read_csv(path_temp, show_col_types = FALSE) %>%
  mutate(
    timestamp_img = ymd_hms(strptime(timestamp, format = "%Y%m%d%H%M%S", tz = "UTC")),
    temperature = as.numeric(temperature)
  ) %>%
  select(deployment_id, timestamp_img, temperature, confidence, extraction_status)

# Compute mean temperature over (t-30, t] per row
compute_temp_mean <- function(dep_id, t_end, t_minutes = 30) {
  if (is.na(dep_id) || is.na(t_end)) return(tibble(ambient_temp_mean = NA_real_, temp_rows_in_window = NA_integer_))
  t_start <- t_end - lubridate::minutes(t_minutes)
  seg <- temps %>% dplyr::filter(deployment_id == dep_id, timestamp_img > t_start, timestamp_img <= t_end)
  tibble(
    ambient_temp_mean = {
      m <- mean(seg$temperature, na.rm = TRUE)
      if (is.nan(m)) NA_real_ else m
    },
    temp_rows_in_window = nrow(seg)
  )
}

temp_tbl <- purrr::map2_dfr(abund_30$deployment_id, abund_30$timestamp, compute_temp_mean)
abund_30 <- dplyr::bind_cols(abund_30, temp_tbl) %>%
  mutate(ambient_temp = ambient_temp_mean)

abund_30 %>% summarise(
  n = n(),
  temp_rows_mean = mean(temp_rows_in_window, na.rm = TRUE),
  temp_available = sum(!is.na(ambient_temp)),
  mean_temp = mean(ambient_temp, na.rm = TRUE)
)
```

## Step 5 — Map Deployments to Wind Meters

```{r}
#| label: map-wind-meter
deps <- readr::read_csv(path_deps, show_col_types = FALSE) %>%
  select(deployment_id, wind_meter_name, view_id, camera_name) %>%
  mutate(
    wind_meter_name = na_if(wind_meter_name, "NA"),
    view = as.character(view_id)
  )

# view is set to view_id as requested.

abund_30 <- abund_30 %>% left_join(deps, by = "deployment_id")

abund_30 %>% count(deployment_id, wind_meter_name) %>% arrange(deployment_id)
```

## Step 6 — Wind Threshold Minutes per 30-min Interval

```{r}
#| label: wind-thresholds
# Read combined per-minute wind, parse timestamps as UTC
wind <- readr::read_csv(path_wind, show_col_types = FALSE) %>%
  mutate(
    time = ymd_hms(time, tz = "UTC", quiet = TRUE),
    speed = as.numeric(speed),
    gust  = as.numeric(gust)
  ) %>%
  select(wind_meter_name, time, speed, gust)

# Helper to compute minutes above threshold within (t-30, t]
compute_thresholds <- function(wm, t_end, t_minutes = 30, thr = 2) {
  if (is.na(wm) || is.na(t_end)) return(tibble(sustained_minutes_above_2ms = NA_integer_, gust_minutes_above_2ms = NA_integer_))
  t_start <- t_end - minutes(t_minutes)
  seg <- wind %>%
    filter(wind_meter_name == wm, time > t_start, time <= t_end)
  tibble(
    wind_rows_in_window         = nrow(seg),
    sustained_minutes_above_2ms = sum(!is.na(seg$speed) & seg$speed > thr),
    gust_minutes_above_2ms      = sum(!is.na(seg$gust)  & seg$gust  > thr)
  )
}

# Vectorized map over each row of abund_30
thr_tbl <- purrr::pmap_dfr(list(abund_30$wind_meter_name, abund_30$timestamp), compute_thresholds)

abund_30 <- bind_cols(abund_30, thr_tbl)

abund_30 %>% select(deployment_id, timestamp, wind_rows_in_window, sustained_minutes_above_2ms, gust_minutes_above_2ms) %>% head(10)
```

## Step 7 — Optional: Drop Empty Intervals (0→0)

```{r}
#| label: drop-empty
abund_30 <- abund_30 %>% mutate(empty_zero_interval = (abundance_index_t_minus_1 == 0 & abundance_index_t == 0))

empty_summary <- abund_30 %>% summarise(
  n = n(),
  zero_zero_n = sum(empty_zero_interval, na.rm = TRUE),
  zero_zero_prop = mean(empty_zero_interval, na.rm = TRUE)
)

empty_summary

if (isTRUE(drop_empty_zero_intervals)) {
  abund_30 <- abund_30 %>% filter(!empty_zero_interval)
}
```

## Output Preview (No Modeling Yet)

```{r}
#| label: preview-output
abund_30 %>%
  transmute(
    deployment_id,
    view,
    timestamp,
    abundance_index_t_minus_1,
    abundance_index_t,
    wind_rows_in_window,
    sustained_minutes_above_2ms,
    gust_minutes_above_2ms,
    sunlight_exposure_prop,
    ambient_temp
  ) %>%
  head(20)
```

## Step 9 — Modeling (GLMM, nbinom2)

```{r}
#| label: build-model-data
# Prepare analysis dataset with required fields, drop remaining NAs
analysis_30 <- abund_30 %>%
  transmute(
    deployment_id,
    view,
    timestamp,
    abundance_index_t,
    abundance_index_t_minus_1,
    sustained_minutes_above_2ms,
    gust_minutes_above_2ms,
    wind_rows_in_window,
    sunlight_exposure_prop,
    ambient_temp
  ) %>%
  filter(
    !is.na(view),
    !is.na(abundance_index_t),
    !is.na(abundance_index_t_minus_1)
  )

# Quick counts and missingness audit for predictors
summary_tbl <- tibble(
  n = nrow(analysis_30),
  na_sun = sum(is.na(analysis_30$sunlight_exposure_prop)),
  na_temp = sum(is.na(analysis_30$ambient_temp)),
  na_sustained = sum(is.na(analysis_30$sustained_minutes_above_2ms)),
  na_gust = sum(is.na(analysis_30$gust_minutes_above_2ms))
)
summary_tbl
```

```{r}
#| label: model-sustained
#| fig-width: 7
# Model with sustained minutes above 2 m/s
model_sustained_threshold <- glmmTMB(
  abundance_index_t ~ abundance_index_t_minus_1 +
    sustained_minutes_above_2ms +
    sunlight_exposure_prop * ambient_temp +
    (1 | view),
  family = nbinom2(),
  data = analysis_30
)

summary(model_sustained_threshold)
performance::r2(model_sustained_threshold)
performance::check_overdispersion(model_sustained_threshold)
performance::check_zeroinflation(model_sustained_threshold)
performance::check_collinearity(model_sustained_threshold)
performance::check_model(model_sustained_threshold)

# Tidy table with CIs
broom.mixed::tidy(model_sustained_threshold, effects = "fixed", conf.int = TRUE)
```

```{r}
#| label: model-gust
#| fig-width: 7
# Model with gust minutes above 2 m/s
model_gust_threshold <- glmmTMB(
  abundance_index_t ~ abundance_index_t_minus_1 +
    gust_minutes_above_2ms +
    sunlight_exposure_prop * ambient_temp +
    (1 | view),
  family = nbinom2(),
  data = analysis_30
)

summary(model_gust_threshold)
performance::r2(model_gust_threshold)
performance::check_overdispersion(model_gust_threshold)
performance::check_zeroinflation(model_gust_threshold)
performance::check_collinearity(model_gust_threshold)
performance::check_model(model_gust_threshold)

# Tidy table with CIs
broom.mixed::tidy(model_gust_threshold, effects = "fixed", conf.int = TRUE)
```

```{r}
#| label: compare-aic
# Compare AIC and R2 side by side
tbl_compare <- tibble(
  model = c("sustained", "gust"),
  AIC = c(AIC(model_sustained_threshold), AIC(model_gust_threshold)),
  R2_marginal = c(performance::r2(model_sustained_threshold)$R2_marginal,
                  performance::r2(model_gust_threshold)$R2_marginal),
  R2_conditional = c(performance::r2(model_sustained_threshold)$R2_conditional,
                     performance::r2(model_gust_threshold)$R2_conditional)
)
tbl_compare
```

## Step 10 — Model Refinements and Alternatives

```{r}
#| label: refinements
# Center/scale predictors to reduce VIF and stabilize interaction estimates

# Guard: ensure wind_rows_in_window exists (fallback to 30 if missing)
if (!"wind_rows_in_window" %in% names(analysis_30)) {
  analysis_30 <- analysis_30 %>% mutate(wind_rows_in_window = 30L)
}

analysis_30_ref <- analysis_30 %>%
  mutate(
    ambient_temp_c = as.numeric(scale(ambient_temp, center = TRUE, scale = TRUE)),
    sunlight_exposure_prop_c = as.numeric(scale(sunlight_exposure_prop, center = TRUE, scale = TRUE)),
    gust_above2_per10 = gust_minutes_above_2ms / 10,
    sustained_above2_per10 = sustained_minutes_above_2ms / 10,
    # proportions within the 30-min window (guard against divide-by-zero)
    gust_prop_above2 = ifelse(is.na(wind_rows_in_window) | wind_rows_in_window == 0, NA_real_, gust_minutes_above_2ms / wind_rows_in_window),
    sustained_prop_above2 = ifelse(is.na(wind_rows_in_window) | wind_rows_in_window == 0, NA_real_, sustained_minutes_above_2ms / wind_rows_in_window)
  ) %>%
  # Sequential time index per view for optional AR1 test
  group_by(view) %>% arrange(timestamp, .by_group = TRUE) %>%
  mutate(time_index = row_number()) %>%
  ungroup()

# Refit with centered predictors (gust)
model_gust_centered <- glmmTMB(
  abundance_index_t ~ abundance_index_t_minus_1 +
    gust_above2_per10 +
    sunlight_exposure_prop_c * ambient_temp_c +
    (1 | view),
  family = nbinom2(),
  data = analysis_30_ref,
  control = glmmTMBControl(optCtrl = list(iter.max = 1e5, eval.max = 1e5))
)

# Refit with centered predictors (sustained)
model_sustained_centered <- glmmTMB(
  abundance_index_t ~ abundance_index_t_minus_1 +
    sustained_above2_per10 +
    sunlight_exposure_prop_c * ambient_temp_c +
    (1 | view),
  family = nbinom2(),
  data = analysis_30_ref,
  control = glmmTMBControl(optCtrl = list(iter.max = 1e5, eval.max = 1e5))
)

# Optional: allow wind effect to vary by view (random slope)
model_gust_rslope <- tryCatch({
  glmmTMB(
    abundance_index_t ~ abundance_index_t_minus_1 +
      gust_above2_per10 +
      sunlight_exposure_prop_c * ambient_temp_c +
      (1 + gust_above2_per10 | view),
    family = nbinom2(),
    data = analysis_30_ref,
    control = glmmTMBControl(optCtrl = list(iter.max = 1e5, eval.max = 1e5))
  )
}, error = function(e) NULL)

# If there are no zeros in response, consider zero-truncated NB
has_zero <- any(analysis_30_ref$abundance_index_t == 0, na.rm = TRUE)
model_gust_trunc <- NULL
if (!has_zero) {
  model_gust_trunc <- glmmTMB(
    abundance_index_t ~ abundance_index_t_minus_1 +
      gust_above2_per10 +
      sunlight_exposure_prop_c * ambient_temp_c +
      (1 | view),
    family = truncated_nbinom2(),
    data = analysis_30_ref,
    control = glmmTMBControl(optCtrl = list(iter.max = 1e5, eval.max = 1e5))
  )
}

# DHARMa residual diagnostics including temporal autocorrelation
set.seed(123)
diag_gust <- DHARMa::simulateResiduals(model_gust_centered, plot = FALSE)
DHARMa::testUniformity(diag_gust)
DHARMa::testDispersion(diag_gust)
DHARMa::testZeroInflation(diag_gust)

# Build a time vector aligned to the rows actually used in the model
mf_gc <- model.frame(model_gust_centered)
# Row names of the model frame typically map to the original row indices
idx_gc <- suppressWarnings(as.integer(rownames(mf_gc)))
if (any(is.na(idx_gc))) {
  # Fallback via na.action mapping
  na_gc <- attr(mf_gc, "na.action")
  if (inherits(na_gc, "omit")) {
    idx_gc <- setdiff(seq_len(nrow(analysis_30_ref)), as.integer(na_gc))
  } else {
    idx_gc <- seq_len(nrow(analysis_30_ref))
  }
}
view_index_gc <- as.numeric(as.factor(analysis_30_ref$view[idx_gc]))
time_for_dharma_gc <- analysis_30_ref$time_index[idx_gc] + view_index_gc * 1e6

# Ensure lengths match residuals
stopifnot(length(residuals(diag_gust)) == length(time_for_dharma_gc))
DHARMa::testTemporalAutocorrelation(diag_gust, time = time_for_dharma_gc)

# If truncated model exists, create aligned time as well and run diagnostics
if (!is.null(model_gust_trunc)) {
  diag_gust_trunc <- DHARMa::simulateResiduals(model_gust_trunc, plot = FALSE)
  DHARMa::testUniformity(diag_gust_trunc)
  DHARMa::testDispersion(diag_gust_trunc)
  DHARMa::testZeroInflation(diag_gust_trunc)

  mf_gt <- model.frame(model_gust_trunc)
  idx_gt <- suppressWarnings(as.integer(rownames(mf_gt)))
  if (any(is.na(idx_gt))) {
    na_gt <- attr(mf_gt, "na.action")
    if (inherits(na_gt, "omit")) {
      idx_gt <- setdiff(seq_len(nrow(analysis_30_ref)), as.integer(na_gt))
    } else {
      idx_gt <- seq_len(nrow(analysis_30_ref))
    }
  }
  view_index_gt <- as.numeric(as.factor(analysis_30_ref$view[idx_gt]))
  time_for_dharma_gt <- analysis_30_ref$time_index[idx_gt] + view_index_gt * 1e6

  stopifnot(length(residuals(diag_gust_trunc)) == length(time_for_dharma_gt))
  DHARMa::testTemporalAutocorrelation(diag_gust_trunc, time = time_for_dharma_gt)
}

# Alternative, simpler variants for robustness
model_gust_additive <- glmmTMB(
  abundance_index_t ~ abundance_index_t_minus_1 +
    gust_above2_per10 +
    sunlight_exposure_prop_c + ambient_temp_c +
    (1 | view),
  family = nbinom2(),
  data = analysis_30_ref,
  control = glmmTMBControl(optCtrl = list(iter.max = 1e5, eval.max = 1e5))
)

model_gust_prop <- glmmTMB(
  abundance_index_t ~ abundance_index_t_minus_1 +
    gust_prop_above2 +
    sunlight_exposure_prop_c * ambient_temp_c +
    (1 | view),
  family = nbinom2(),
  data = analysis_30_ref,
  control = glmmTMBControl(optCtrl = list(iter.max = 1e5, eval.max = 1e5))
)

# Growth-offset model: abundance change rate
model_gust_growth <- glmmTMB(
  abundance_index_t ~ 
    gust_above2_per10 +
    sunlight_exposure_prop_c * ambient_temp_c +
    (1 | view) +
    offset(log(pmax(abundance_index_t_minus_1, 0) + 1)),
  family = nbinom2(),
  data = analysis_30_ref,
  control = glmmTMBControl(optCtrl = list(iter.max = 1e5, eval.max = 1e5))
)

# Compare models where available
models_named <- list(
  gust_baseline          = model_gust_threshold,
  sustained_baseline     = model_sustained_threshold,
  gust_centered          = model_gust_centered,
  sustained_centered     = model_sustained_centered,
  gust_random_slope      = model_gust_rslope,
  gust_truncated         = model_gust_trunc,
  gust_additive          = model_gust_additive,
  gust_proportion        = model_gust_prop,
  gust_growth_offset     = model_gust_growth
)
# Drop NULL models (e.g., truncated when zeros exist)
models_named <- models_named[!vapply(models_named, is.null, logical(1))]

cmp <- performance::compare_performance(models_named, rank = TRUE)
cmp

# Pick top-ranked model by AIC/weights
top_name <- cmp$Name[1]
top_model <- models_named[[top_name]]

# Quick singularity / diagnostics summary
list(
  selected = top_name,
  r2 = performance::r2(top_model),
  overdisp = performance::check_overdispersion(top_model),
  zeroinfl = try(performance::check_zeroinflation(top_model), silent = TRUE),
  collinearity = performance::check_collinearity(top_model)
)

# Tidy with IRR where applicable
tidy_top <- broom.mixed::tidy(top_model, effects = "fixed", conf.int = TRUE)

# Identify wind term and compute IRR for meaningful scale
wind_terms <- c("gust_above2_per10", "gust_minutes_above_2ms", "sustained_minutes_above_2ms", "sustained_above2_per10", "gust_prop_above2", "sustained_prop_above2")
present_wind <- intersect(wind_terms, tidy_top$term)
if (length(present_wind) > 0) {
  wt <- present_wind[1]
  row <- dplyr::filter(tidy_top, term == wt)
  # scale note
  scale_note <- dplyr::case_when(
    wt %in% c("gust_above2_per10","sustained_above2_per10") ~ "per +10 minutes",
    wt %in% c("gust_minutes_above_2ms","sustained_minutes_above_2ms") ~ "per +1 minute",
    wt %in% c("gust_prop_above2","sustained_prop_above2") ~ "per +0.1 proportion (10%)"
  )
  irr <- exp(row$estimate)
  irr_low <- exp(row$conf.low)
  irr_high <- exp(row$conf.high)
  tibble(
    wind_term = wt,
    scale = scale_note,
    estimate = row$estimate,
    IRR = irr,
    IRR_low = irr_low,
    IRR_high = irr_high,
    p_value = row$p.value
  ) -> irr_selected
} else {
  tibble(note = "No wind term found in selected model") -> irr_selected
}

# Export comparison and IRR in console-friendly formats
readr::write_csv(cmp, file = "results/model_comparison.csv")
if (exists("irr_selected") && nrow(irr_selected) > 0 && !"note" %in% names(irr_selected)) {
  readr::write_csv(irr_selected, file = "results/irr_selected.csv")
  irr_json <- list(
    selected_model = top_name,
    wind_term = irr_selected$wind_term[[1]],
    scale = irr_selected$scale[[1]],
    estimate = irr_selected$estimate[[1]],
    IRR = irr_selected$IRR[[1]],
    IRR_low = irr_selected$IRR_low[[1]],
    IRR_high = irr_selected$IRR_high[[1]],
    p_value = irr_selected$p_value[[1]]
  )
  writeLines(jsonlite::toJSON(irr_json, auto_unbox = TRUE, digits = 6), con = "results/irr_selected.json")
  cat(sprintf(
    "selected_model: %s\nwind_term: %s\nscale: %s\nestimate: %.6f\nIRR_scaled: %.4f [%.4f, %.4f]\np.value: %.3g\n",
    top_name,
    irr_selected$wind_term[[1]],
    irr_selected$scale[[1]],
    irr_selected$estimate[[1]],
    irr_selected$IRR[[1]], irr_selected$IRR_low[[1]], irr_selected$IRR_high[[1]],
    irr_selected$p_value[[1]]
  ))
} else {
  cat("No wind effect available to export for selected model.\n")
}

# Tidy summaries (centered models)
broom.mixed::tidy(model_gust_centered, effects = "fixed", conf.int = TRUE)
broom.mixed::tidy(model_sustained_centered, effects = "fixed", conf.int = TRUE)
```

## Notes / Questions for Kyle

- Confirm `view`: should we use `view_id` from `deployments.csv`, or a different grouping for the random intercept? If a separate mapping exists, where is it stored?
- Confirm wind interval: using the 30 minutes immediately preceding the image at time t (open t-30, closed t). Should it instead be the closed interval [t-30, t]? Current implementation uses (t-30, t].
- Confirm temperature: joined exactly at image time t. Would you prefer the mean temperature over (t-30, t] instead?
- Empty intervals: by default not dropped. Do you want them removed for Hypothesis 1?
- Abundance source: we are reading `data/butterfly_abundance_index.csv`. Should we recompute from JSON each run, or rely on this export for consistency?

```

## Summary So Far

- Data assembly: 30-min consecutive pairs within deployment, `abundance_index_t` and true lag `abundance_index_t_minus_1`, `view = view_id` from `deployments.csv`.
- Windows: wind metrics derived over (t-30, t], using all available per-minute rows; exported `wind_rows_in_window` for QA. Temperature uses mean over (t-30, t].
- Wind metrics: both minutes-above-2 m/s and proportion-above-2 m/s computed for sustained and gust; proportion normalizes for any variation in minute counts.
- Filtering: removed empty 0→0 intervals to focus on periods with monarch presence; abundance always loaded from `data/butterfly_abundance_index.csv`.
- Modeling (count scale): negative binomial GLMMs with random intercept for `view`. Centering predictors reduced VIF; no material overdispersion observed; zero-deflation expected due to 0→0 removal. Among count-scale models, the gust proportion model ranked best by AIC/BIC and produced a negative wind effect.
- Key estimate (count scale): for `gust_prop_above2`, IRR per +10% ≈ 0.79 (95% CI ≈ 0.69–0.91), p ≈ 0.0008 — indicating a ~21% decrease in expected abundance for each 10% increase in gust > 2 m/s in the prior 30 minutes, holding covariates constant.
- Modeling (growth rate): growth-offset variant substantially improved AIC relative to count-scale lag models. With minutes/10, the gust effect was near-zero and non-significant; we recommend testing the growth-offset with gust proportion for theory-aligned inference on step-to-step change.
- Diagnostics: DHARMa checks added with alignment of time indices to model-used rows for temporal autocorrelation tests; random-slope variants sometimes singular and are optional.
- Exports: model comparison and selected wind IRR are saved to `results/` (CSV + JSON) and printed in a console-friendly format.

Next steps (optional)

- Fit/export the growth-offset model using `gust_prop_above2` (and optionally `sustained_prop_above2`) and report IRR per +10% with diagnostics.
- Summarize sensitivity across: count-scale proportion vs growth-offset proportion; additive vs interaction; (optionally) truncated NB when zeros are absent.
- If temporal autocorrelation persists in DHARMa, consider an AR1 residual structure as a final refinement.
